23:43:57.263 [I] Running on: babel-5-11                                                           (353335:train.py:254)
23:43:58.246 [I] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig' (353335:xla_bridge.py:945)
23:43:58.259 [I] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory (353335:xla_bridge.py:945)
23:43:59.290 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (353335:base_pytree_checkpoint_handler.py:332)
23:43:59.290 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (353335:base_pytree_checkpoint_handler.py:332)
23:43:59.290 [I] [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID. (353335:multihost.py:375)
23:43:59.290 [I] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers={'assets': <openpi.training.checkpoints.CallbackHandler object at 0x148ad43acc90>, 'train_state': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad417ab10>, 'params': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad4179890>}, handler_registry=None (353335:checkpoint_manager.py:622)
23:43:59.290 [I] Deferred registration for item: "assets". Adding handler `<openpi.training.checkpoints.CallbackHandler object at 0x148ad43acc90>` for item "assets" and save args `<class 'openpi.training.checkpoints.CallbackSave'>` and restore args `<class 'openpi.training.checkpoints.CallbackRestore'>` to `_handler_registry`. (353335:composite_checkpoint_handler.py:239)
23:43:59.290 [I] Deferred registration for item: "train_state". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad417ab10>` for item "train_state" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (353335:composite_checkpoint_handler.py:239)
23:43:59.290 [I] Deferred registration for item: "params". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad4179890>` for item "params" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (353335:composite_checkpoint_handler.py:239)
23:43:59.290 [I] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x148ad4061590>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`. (353335:composite_checkpoint_handler.py:239)
23:43:59.290 [I] Initialized registry DefaultCheckpointHandlerRegistry({('assets', <class 'openpi.training.checkpoints.CallbackSave'>): <openpi.training.checkpoints.CallbackHandler object at 0x148ad43acc90>, ('assets', <class 'openpi.training.checkpoints.CallbackRestore'>): <openpi.training.checkpoints.CallbackHandler object at 0x148ad43acc90>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad417ab10>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad417ab10>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad4179890>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x148ad4179890>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x148ad4061590>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x148ad4061590>}). (353335:composite_checkpoint_handler.py:508)
23:43:59.291 [I] orbax-checkpoint version: 0.11.1                                                 (353335:abstract_checkpointer.py:35)
23:43:59.291 [I] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x148ad43f2f20> timeout: 7200 secs and primary_host=0 for async checkpoint writes (353335:async_checkpointer.py:80)
23:43:59.291 [I] Found 0 checkpoint steps in /data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer_subgoal/shoes_full_test (353335:checkpoint_manager.py:1528)
23:43:59.291 [I] Saving root metadata                                                             (353335:checkpoint_manager.py:1569)
23:43:59.291 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: CheckpointManager:save_metadata (353335:multihost.py:293)
23:43:59.291 [I] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=5000, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=AsyncOptions(timeout_secs=7200, barrier_sync_fn=None, post_finalization_callback=None, create_directories_asynchronously=False), multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None), root_directory=/data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer_subgoal/shoes_full_test: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x148ad4178d50> (353335:checkpoint_manager.py:797)
23:44:00.706 [I] Loaded norm stats from /data/user_data/mbronars/packages/openpi/assets/pi0_hiveformer_subgoal/hiveformer_keypose (353335:config.py:174)
23:44:00.902 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (353335:_snapshot_download.py:213)
23:44:00.906 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (353335:_snapshot_download.py:213)
23:44:00.908 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (353335:_snapshot_download.py:213)
23:44:26.820 [I] Initialized data loader:
[0].images['base_0_rgb']: (64, 224, 224, 3)@float32
[0].images['left_wrist_0_rgb']: (64, 224, 224, 3)@float32
[0].images['right_wrist_0_rgb']: (64, 224, 224, 3)@float32
[0].image_masks['base_0_rgb']: (64,)@bool
[0].image_masks['left_wrist_0_rgb']: (64,)@bool
[0].image_masks['right_wrist_0_rgb']: (64,)@bool
[0].state: (64, 32)@float32
[0].segmentations['base_0_seg']: (64, 224, 224)@bool
[0].segmentations['left_wrist_0_seg']: (64, 224, 224)@bool
[0].segmentations['right_wrist_0_seg']: (64, 224, 224)@bool
[0].segmentation_masks['base_0_seg']: (64,)@bool
[0].segmentation_masks['left_wrist_0_seg']: (64,)@bool
[0].segmentation_masks['right_wrist_0_seg']: (64,)@bool
[0].tokenized_subtask: (64, 48)@int32
[0].tokenized_subtask_mask: (64, 48)@bool
[0].tokenized_prompt: (64, 48)@int32
[0].tokenized_prompt_mask: (64, 48)@bool
[1]: (64, 1, 32)@float32 (353335:train.py:292)
23:44:27.925 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.926 [I] Sharding .params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.927 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.928 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.929 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.929 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.929 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.929 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.930 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.931 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.932 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.933 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.933 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.933 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.933 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.933 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.934 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.935 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.936 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.937 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.938 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.939 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.940 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.941 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.942 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.943 [I] Sharding .opt_state[1][0].nu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.944 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.945 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.946 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.947 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.948 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.948 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.948 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.948 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.948 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.949 [I] Sharding .ema_params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (353335:sharding.py:89)
23:44:27.950 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.951 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.952 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.953 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.954 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.955 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (353335:sharding.py:89)
23:44:27.960 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (353335:base_pytree_checkpoint_handler.py:332)
23:44:28.005 [I] Restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (353335:checkpointer.py:256)
23:44:43.185 [I] [process=0] /jax/checkpoint/read/bytes_per_sec: 813.8 MiB/s (total bytes: 12.1 GiB) (time elapsed: 15 seconds) (per-host) (353335:base_pytree_checkpoint_handler.py:113)
23:44:43.185 [I] Finished restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (353335:checkpointer.py:259)
23:44:43.186 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:restore (353335:multihost.py:293)
23:44:52.802 [I] Initialized train state:
['PaliGemma']['img']['Transformer']['encoder_norm']['bias'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoder_norm']['scale'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['bias'].value: (27, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value: (27, 1152, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value: (27, 4304, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value: (27, 16, 72, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['embedding']['bias'].value: (1152,)@float32
['PaliGemma']['img']['embedding']['kernel'].value: (14, 14, 3, 1152)@float32
['PaliGemma']['img']['head']['bias'].value: (2048,)@float32
['PaliGemma']['img']['head']['kernel'].value: (1152, 2048)@float32
['PaliGemma']['img']['pos_embedding'].value: (1, 256, 1152)@float32
['PaliGemma']['llm']['embedder']['input_embedding'].value: (257152, 2048)@float32
['PaliGemma']['llm']['final_norm']['scale'].value: (2048,)@float32
['PaliGemma']['llm']['final_norm_1']['scale'].value: (1024,)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value: (18, 8, 256, 2048)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value: (18, 8, 256, 1024)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value: (18, 2, 1, 2048, 256)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value: (18, 2, 1, 1024, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value: (18, 8, 2048, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value: (18, 8, 1024, 256)@float32
['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value: (18, 2, 2048, 16384)@float32
['PaliGemma']['llm']['layers']['mlp']['linear'].value: (18, 16384, 2048)@float32
['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value: (18, 2, 1024, 4096)@float32
['PaliGemma']['llm']['layers']['mlp_1']['linear'].value: (18, 4096, 1024)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm']['scale'].value: (18, 2048)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm_1']['scale'].value: (18, 1024)@float32
['PaliGemma']['llm']['layers']['pre_ffw_norm']['scale'].value: (18, 2048)@float32
['PaliGemma']['llm']['layers']['pre_ffw_norm_1']['scale'].value: (18, 1024)@float32
['action_in_proj']['bias'].value: (1024,)@float32
['action_in_proj']['kernel'].value: (32, 1024)@float32
['action_out_proj']['bias'].value: (32,)@float32
['action_out_proj']['kernel'].value: (1024, 32)@float32
['action_time_mlp_in']['bias'].value: (1024,)@float32
['action_time_mlp_in']['kernel'].value: (2048, 1024)@float32
['action_time_mlp_out']['bias'].value: (1024,)@float32
['action_time_mlp_out']['kernel'].value: (1024, 1024)@float32
['mask_decoder']['conv_up_1']['bias'].value: (512,)@float32
['mask_decoder']['conv_up_1']['kernel'].value: (2, 2, 2048, 512)@float32
['mask_decoder']['conv_up_2']['bias'].value: (256,)@float32
['mask_decoder']['conv_up_2']['kernel'].value: (2, 2, 512, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_0']['bias'].value: (256,)@float32
['mask_decoder']['iou_head']['layers']['layer_0']['kernel'].value: (2048, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_1']['bias'].value: (256,)@float32
['mask_decoder']['iou_head']['layers']['layer_1']['kernel'].value: (256, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_2']['bias'].value: (2,)@float32
['mask_decoder']['iou_head']['layers']['layer_2']['kernel'].value: (256, 2)@float32
['mask_decoder']['iou_token']['embedding'].value: (1, 2048)@float32
['mask_decoder']['ln_up_1']['bias'].value: (512,)@float32
['mask_decoder']['ln_up_1']['weight'].value: (512,)@float32
['mask_decoder']['mask_tokens']['embedding'].value: (2, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_2']['bias'].value: (256,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_2']['kernel'].value: (2048, 256)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_2']['bias'].value: (256,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_2']['kernel'].value: (2048, 256)@float32
['mask_decoder']['transformer']['final_attn']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['final_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['final_attn']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['final_attn']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm1']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm2']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm3']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm3']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm4']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm4']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm1']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm2']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm3']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm3']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm4']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm4']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['norm_final']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['norm_final']['scale'].value: (2048,)@float32
['prompt_encoder']['mask_conv1']['bias'].value: (4,)@float32
['prompt_encoder']['mask_conv1']['kernel'].value: (2, 2, 1, 4)@float32
['prompt_encoder']['mask_conv2']['bias'].value: (16,)@float32
['prompt_encoder']['mask_conv2']['kernel'].value: (2, 2, 4, 16)@float32
['prompt_encoder']['mask_conv3']['bias'].value: (2048,)@float32
['prompt_encoder']['mask_conv3']['kernel'].value: (1, 1, 16, 2048)@float32
['prompt_encoder']['mask_ln1']['bias'].value: (4,)@float32
['prompt_encoder']['mask_ln1']['weight'].value: (4,)@float32
['prompt_encoder']['mask_ln2']['bias'].value: (16,)@float32
['prompt_encoder']['mask_ln2']['weight'].value: (16,)@float32
['prompt_encoder']['no_mask_embed']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['not_a_point_embed']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['pe_layer']['gauss'].value: (2, 1024)@float32
['prompt_encoder']['point_embeddings']['point_emb_0']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_1']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_2']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_3']['embedding'].value: (1, 2048)@float32
['seg_tokens'].value: (1, 3, 2048)@float32
['state_proj']['bias'].value: (1024,)@float32
['state_proj']['kernel'].value: (32, 1024)@float32 (353335:train.py:296)
23:44:52.906 [I] Progress on: -/30000 rate:- remaining:? elapsed:00:00 postfix:-                  (353335:tqdm_logging.py:145)
23:45:10.451 [I] Progress on: -/30000 rate:- remaining:? elapsed:00:17 postfix:-                  (353335:tqdm_logging.py:145)
23:45:10.452 [I] Step 0: grad_norm=67.7580, loss=5.1946, param_norm=1403.1893                     (353335:train.py:326)
23:45:23.425 [I] Progress on: 4.00it/30.0kit rate:6.0s/it remaining:50:00:07 elapsed:00:30 postfix:- (353335:tqdm_logging.py:145)
23:45:35.149 [I] Progress on: 7.00it/30.0kit rate:4.5s/it remaining:37:29:30 elapsed:00:42 postfix:- (353335:tqdm_logging.py:145)
23:45:47.068 [I] Progress on: 10.0it/30.0kit rate:4.1s/it remaining:34:31:02 elapsed:00:54 postfix:- (353335:tqdm_logging.py:145)
23:45:58.989 [I] Progress on: 13.0it/30.0kit rate:4.0s/it remaining:33:36:12 elapsed:01:06 postfix:- (353335:tqdm_logging.py:145)
23:46:10.992 [I] Progress on: 16.0it/30.0kit rate:4.0s/it remaining:33:27:58 elapsed:01:18 postfix:- (353335:tqdm_logging.py:145)
23:46:23.369 [I] Progress on: 19.0it/30.0kit rate:4.0s/it remaining:33:36:43 elapsed:01:30 postfix:- (353335:tqdm_logging.py:145)
23:46:35.536 [I] Progress on: 22.0it/30.0kit rate:4.0s/it remaining:33:37:47 elapsed:01:42 postfix:- (353335:tqdm_logging.py:145)
23:46:47.866 [I] Progress on: 25.0it/30.0kit rate:4.1s/it remaining:34:04:35 elapsed:01:54 postfix:- (353335:tqdm_logging.py:145)
23:47:00.040 [I] Progress on: 28.0it/30.0kit rate:4.1s/it remaining:33:58:35 elapsed:02:07 postfix:- (353335:tqdm_logging.py:145)
23:47:12.208 [I] Progress on: 31.0it/30.0kit rate:4.1s/it remaining:33:48:54 elapsed:02:19 postfix:- (353335:tqdm_logging.py:145)
23:47:25.414 [I] Progress on: 34.0it/30.0kit rate:4.4s/it remaining:36:14:32 elapsed:02:32 postfix:- (353335:tqdm_logging.py:145)
23:47:37.226 [I] Progress on: 37.0it/30.0kit rate:4.1s/it remaining:34:15:10 elapsed:02:44 postfix:- (353335:tqdm_logging.py:145)
23:47:49.554 [I] Progress on: 40.0it/30.0kit rate:4.1s/it remaining:34:07:48 elapsed:02:56 postfix:- (353335:tqdm_logging.py:145)
23:48:01.968 [I] Progress on: 43.0it/30.0kit rate:4.1s/it remaining:34:15:49 elapsed:03:09 postfix:- (353335:tqdm_logging.py:145)
23:48:14.356 [I] Progress on: 46.0it/30.0kit rate:4.1s/it remaining:34:21:43 elapsed:03:21 postfix:- (353335:tqdm_logging.py:145)
23:48:26.687 [I] Progress on: 49.0it/30.0kit rate:4.1s/it remaining:34:18:08 elapsed:03:33 postfix:- (353335:tqdm_logging.py:145)
23:48:39.492 [I] Progress on: 52.0it/30.0kit rate:4.2s/it remaining:34:41:31 elapsed:03:46 postfix:- (353335:tqdm_logging.py:145)
23:48:52.028 [I] Progress on: 55.0it/30.0kit rate:4.2s/it remaining:34:49:28 elapsed:03:59 postfix:- (353335:tqdm_logging.py:145)
23:49:04.386 [I] Progress on: 58.0it/30.0kit rate:4.1s/it remaining:34:29:16 elapsed:04:11 postfix:- (353335:tqdm_logging.py:145)
23:49:16.865 [I] Progress on: 61.0it/30.0kit rate:4.1s/it remaining:34:28:24 elapsed:04:23 postfix:- (353335:tqdm_logging.py:145)
23:49:29.388 [I] Progress on: 64.0it/30.0kit rate:4.2s/it remaining:34:34:41 elapsed:04:36 postfix:- (353335:tqdm_logging.py:145)
23:49:41.915 [I] Progress on: 67.0it/30.0kit rate:4.2s/it remaining:34:43:23 elapsed:04:49 postfix:- (353335:tqdm_logging.py:145)
23:49:54.785 [I] Progress on: 70.0it/30.0kit rate:4.2s/it remaining:34:52:36 elapsed:05:01 postfix:- (353335:tqdm_logging.py:145)
23:50:07.339 [I] Progress on: 73.0it/30.0kit rate:4.2s/it remaining:34:43:18 elapsed:05:14 postfix:- (353335:tqdm_logging.py:145)
23:50:20.052 [I] Progress on: 76.0it/30.0kit rate:4.2s/it remaining:35:09:01 elapsed:05:27 postfix:- (353335:tqdm_logging.py:145)
23:50:32.468 [I] Progress on: 79.0it/30.0kit rate:4.2s/it remaining:34:44:33 elapsed:05:39 postfix:- (353335:tqdm_logging.py:145)
23:50:45.028 [I] Progress on: 82.0it/30.0kit rate:4.2s/it remaining:34:42:12 elapsed:05:52 postfix:- (353335:tqdm_logging.py:145)
346 [I] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig' (1043632:xla_bridge.py:945)
23:50:40.362 [I] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory (1043632:xla_bridge.py:945)
23:50:41.719 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (1043632:base_pytree_checkpoint_handler.py:332)
23:50:41.720 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (1043632:base_pytree_checkpoint_handler.py:332)
23:50:41.720 [I] [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID. (1043632:multihost.py:375)
23:50:41.720 [I] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers={'assets': <openpi.training.checkpoints.CallbackHandler object at 0x15166e4d4e90>, 'train_state': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e562390>, 'params': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e4d71d0>}, handler_registry=None (1043632:checkpoint_manager.py:622)
23:50:41.720 [I] Deferred registration for item: "assets". Adding handler `<openpi.training.checkpoints.CallbackHandler object at 0x15166e4d4e90>` for item "assets" and save args `<class 'openpi.training.checkpoints.CallbackSave'>` and restore args `<class 'openpi.training.checkpoints.CallbackRestore'>` to `_handler_registry`. (1043632:composite_checkpoint_handler.py:239)
23:50:41.720 [I] Deferred registration for item: "train_state". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e562390>` for item "train_state" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (1043632:composite_checkpoint_handler.py:239)
23:50:41.720 [I] Deferred registration for item: "params". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e4d71d0>` for item "params" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (1043632:composite_checkpoint_handler.py:239)
23:50:41.721 [I] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x15166e582d10>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`. (1043632:composite_checkpoint_handler.py:239)
23:50:41.721 [I] Initialized registry DefaultCheckpointHandlerRegistry({('assets', <class 'openpi.training.checkpoints.CallbackSave'>): <openpi.training.checkpoints.CallbackHandler object at 0x15166e4d4e90>, ('assets', <class 'openpi.training.checkpoints.CallbackRestore'>): <openpi.training.checkpoints.CallbackHandler object at 0x15166e4d4e90>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e562390>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e562390>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e4d71d0>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x15166e4d71d0>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x15166e582d10>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x15166e582d10>}). (1043632:composite_checkpoint_handler.py:508)
23:50:41.721 [I] orbax-checkpoint version: 0.11.1                                                 (1043632:abstract_checkpointer.py:35)
23:50:41.721 [I] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x15166e832f20> timeout: 7200 secs and primary_host=0 for async checkpoint writes (1043632:async_checkpointer.py:80)
23:50:41.722 [I] Found 0 checkpoint steps in /data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer/shoes_full_test_no_subgoal (1043632:checkpoint_manager.py:1528)
23:50:41.722 [I] Saving root metadata                                                             (1043632:checkpoint_manager.py:1569)
23:50:41.723 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: CheckpointManager:save_metadata (1043632:multihost.py:293)
23:50:41.723 [I] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=5000, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=AsyncOptions(timeout_secs=7200, barrier_sync_fn=None, post_finalization_callback=None, create_directories_asynchronously=False), multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None), root_directory=/data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer/shoes_full_test_no_subgoal: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x15166e8d5b10> (1043632:checkpoint_manager.py:797)
23:50:43.209 [I] Loaded norm stats from /data/user_data/mbronars/packages/openpi/assets/pi0_hiveformer/hiveformer_keypose (1043632:config.py:174)
23:50:43.269 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (1043632:_snapshot_download.py:213)
23:50:43.274 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (1043632:_snapshot_download.py:213)
23:50:43.276 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (1043632:_snapshot_download.py:213)
                                                                                                                                                                                                                                                                    23:51:24.140 [I] Initialized data loader:
[0].images['base_0_rgb']: (64, 224, 224, 3)@float32
[0].images['left_wrist_0_rgb']: (64,23:51:35.637 [I] Progress on: 94.0it/30.0kit rate:4.2s/it remaining:34:40:29 elapsed:06:42 postfix:- (353335:tqdm_logging.py:145)
ge_masks['left_wrist_0_rgb']: (64,)@bool
[0].image_masks['right_wrist_0_rgb']: (64,)@bool
[0].state: (64, 32)@float32
[0].tokenized_prompt: (64, 48)@int32
[0].tokenized_prompt_mask: (64, 48)@bool
[1]: (64, 1, 32)@float32 (1043632:train.py:292)
23:51:25.387 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.388 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.388 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.389 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.389 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.390 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.390 [I] Sharding .params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.390 [I] Sharding .params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.391 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.391 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.391 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.391 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.392 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.392 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.392 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.393 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.393 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.393 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.394 [I] Sharding .params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.394 [I] Sharding .params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.395 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.395 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.395 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.396 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.396 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.396 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.397 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.397 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.397 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.397 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.398 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.398 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.399 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.399 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.399 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.400 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.400 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.400 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.401 [I] Sharding .opt_state[1][0].mu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.401 [I] Sharding .opt_state[1][0].mu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.402 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.402 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.402 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.403 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.403 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.403 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.403 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.404 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.404 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.404 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.405 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.405 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.405 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.405 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.406 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.406 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.406 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.406 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.407 [I] Sharding .opt_state[1][0].nu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.407 [I] Sharding .opt_state[1][0].nu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.408 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.408 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.408 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.409 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.409 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.409 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.409 [I] Sharding .ema_params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.410 [I] Sharding .ema_params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.410 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.410 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.410 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.411 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.411 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.411 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (1043632:sharding.py:89)
23:51:25.411 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.412 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.412 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (1043632:sharding.py:89)
23:51:25.412 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.413 [I] Sharding .ema_params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (1043632:sharding.py:89)
23:51:25.413 [I] Sharding .ema_params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (1043632:sharding.py:89)
23:51:25.418 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (1043632:base_pytree_checkpoint_handler.py:332)
23:51:25.474 [I] Restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (1043632:checkpointer.py:256)
23:51:48.354 [I] Progress on: 97.0it/30.0kit rate:4.2s/it remaining:35:06:47 elapsed:06:55 postfix:- (353335:tqdm_logging.py:145)
er-host) (1043632:base_pytree_checkpoint_handler.py:113)
23:51:46.268 [I] Finished restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (1043632:checkpointer.py:259)
23:51:46.268 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:restore (1043632:multihost.py:293)
23:52:00.851 [I] Progress on: 100it/30.0kit rate:4.2s/it remaining:34:34:44 elapsed:07:07 postfix:- (353335:tqdm_logging.py:145)
23:52:05.632 [I] Step 100: grad_norm=nan, loss=nan, param_norm=nan                                (353335:train.py:326)
23:52:13.929 [I] Progress on: 103it/30.0kit rate:4.2s/it remaining:34:53:27 elapsed:07:21 postfix:- (353335:tqdm_logging.py:145)
23:52:26.682 [I] Progress on: 106it/30.0kit rate:4.2s/it remaining:35:15:16 elapsed:07:33 postfix:- (353335:tqdm_logging.py:145)
23:52:39.136 [I] Progress on: 109it/30.0kit rate:4.2s/it remaining:34:50:13 elapsed:07:46 postfix:- (353335:tqdm_logging.py:145)
23:52:51.751 [I] Progress on: 112it/30.0kit rate:4.2s/it remaining:34:49:11 elapsed:07:58 postfix:- (353335:tqdm_logging.py:145)
23:53:04.362 [I] Progress on: 115it/30.0kit rate:4.2s/it remaining:34:46:17 elapsed:08:11 postfix:- (353335:tqdm_logging.py:145)
23:53:17.005 [I] Progress on: 118it/30.0kit rate:4.2s/it remaining:34:56:25 elapsed:08:24 postfix:- (353335:tqdm_logging.py:145)
23:53:29.916 [I] Progress on: 121it/30.0kit rate:4.2s/it remaining:35:00:45 elapsed:08:37 postfix:- (353335:tqdm_logging.py:145)
23:54:56.726 [I] Running on: babel-5-11                                                           (354203:train.py:254)
23:54:57.344 [I] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig' (354203:xla_bridge.py:945)
23:54:57.345 [I] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory (354203:xla_bridge.py:945)
23:54:57.671 [I] Wiped checkpoint directory /data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer_subgoal/shoes_full_test (354203:checkpoints.py:25)
23:54:57.671 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (354203:base_pytree_checkpoint_handler.py:332)
23:54:57.672 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (354203:base_pytree_checkpoint_handler.py:332)
23:54:57.672 [I] [thread=MainThread] Failed to get flag value for EXPERIMENTAL_ORBAX_USE_DISTRIBUTED_PROCESS_ID. (354203:multihost.py:375)
23:54:57.672 [I] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=None, item_handlers={'assets': <openpi.training.checkpoints.CallbackHandler object at 0x14db542e61d0>, 'train_state': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14db5437a050>, 'params': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14dc48fa2890>}, handler_registry=None (354203:checkpoint_manager.py:622)
23:54:57.672 [I] Deferred registration for item: "assets". Adding handler `<openpi.training.checkpoints.CallbackHandler object at 0x14db542e61d0>` for item "assets" and save args `<class 'openpi.training.checkpoints.CallbackSave'>` and restore args `<class 'openpi.training.checkpoints.CallbackRestore'>` to `_handler_registry`. (354203:composite_checkpoint_handler.py:239)
23:54:57.672 [I] Deferred registration for item: "train_state". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14db5437a050>` for item "train_state" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (354203:composite_checkpoint_handler.py:239)
23:54:57.672 [I] Deferred registration for item: "params". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14dc48fa2890>` for item "params" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`. (354203:composite_checkpoint_handler.py:239)
23:54:57.672 [I] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14db54336810>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`. (354203:composite_checkpoint_handler.py:239)
23:54:57.672 [I] Initialized registry DefaultCheckpointHandlerRegistry({('assets', <class 'openpi.training.checkpoints.CallbackSave'>): <openpi.training.checkpoints.CallbackHandler object at 0x14db542e61d0>, ('assets', <class 'openpi.training.checkpoints.CallbackRestore'>): <openpi.training.checkpoints.CallbackHandler object at 0x14db542e61d0>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14db5437a050>, ('train_state', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14db5437a050>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14dc48fa2890>, ('params', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x14dc48fa2890>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14db54336810>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x14db54336810>}). (354203:composite_checkpoint_handler.py:508)
23:54:57.673 [I] orbax-checkpoint version: 0.11.1                                                 (354203:abstract_checkpointer.py:35)
23:54:57.673 [I] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>.<lambda> at 0x14db54586f20> timeout: 7200 secs and primary_host=0 for async checkpoint writes (354203:async_checkpointer.py:80)
23:54:57.673 [I] Found 0 checkpoint steps in /data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer_subgoal/shoes_full_test (354203:checkpoint_manager.py:1528)
23:54:57.673 [I] Saving root metadata                                                             (354203:checkpoint_manager.py:1569)
23:54:57.673 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: CheckpointManager:save_metadata (354203:multihost.py:293)
23:54:57.673 [I] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=1, max_to_keep=1, keep_time_interval=None, keep_period=5000, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=False, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=AsyncOptions(timeout_secs=7200, barrier_sync_fn=None, post_finalization_callback=None, create_directories_asynchronously=False), multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None), root_directory=/data/user_data/mbronars/packages/openpi/checkpoints/pi0_hiveformer_subgoal/shoes_full_test: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x14db5427afd0> (354203:checkpoint_manager.py:797)
23:54:58.622 [I] Loaded norm stats from /data/user_data/mbronars/packages/openpi/assets/pi0_hiveformer_subgoal/hiveformer_keypose (354203:config.py:174)
23:54:58.668 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (354203:_snapshot_download.py:213)
23:54:58.672 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (354203:_snapshot_download.py:213)
23:54:58.673 [W] Returning existing local_dir `/data/group_data/katefgroup/VLA/lerobot_datasets/shoes_subgoal` as remote repo cannot be accessed in `snapshot_download` (None). (354203:_snapshot_download.py:213)
23:55:20.690 [I] Initialized data loader:
[0].images['base_0_rgb']: (64, 224, 224, 3)@float32
[0].images['left_wrist_0_rgb']: (64, 224, 224, 3)@float32
[0].images['right_wrist_0_rgb']: (64, 224, 224, 3)@float32
[0].image_masks['base_0_rgb']: (64,)@bool
[0].image_masks['left_wrist_0_rgb']: (64,)@bool
[0].image_masks['right_wrist_0_rgb']: (64,)@bool
[0].state: (64, 32)@float32
[0].segmentations['base_0_seg']: (64, 224, 224)@bool
[0].segmentations['left_wrist_0_seg']: (64, 224, 224)@bool
[0].segmentations['right_wrist_0_seg']: (64, 224, 224)@bool
[0].segmentation_masks['base_0_seg']: (64,)@bool
[0].segmentation_masks['left_wrist_0_seg']: (64,)@bool
[0].segmentation_masks['right_wrist_0_seg']: (64,)@bool
[0].tokenized_subtask: (64, 48)@int32
[0].tokenized_subtask_mask: (64, 48)@bool
[0].tokenized_prompt: (64, 48)@int32
[0].tokenized_prompt_mask: (64, 48)@bool
[1]: (64, 1, 32)@float32 (354203:train.py:292)
23:55:21.660 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.660 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.660 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.661 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.662 [I] Sharding .params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.663 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.664 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.665 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.666 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.667 [I] Sharding .params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.668 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.668 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.669 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.670 [I] Sharding .opt_state[1][0].mu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.671 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.672 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.673 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.674 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.675 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.676 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.676 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.676 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.676 [I] Sharding .opt_state[1][0].mu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.676 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.677 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.678 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.679 [I] Sharding .opt_state[1][0].nu['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.680 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.681 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.682 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.683 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .opt_state[1][0].nu['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value of shape (27, 1152, 4304) (510.68 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.684 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value of shape (27, 4304, 1152) (510.68 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value of shape (27, 16, 72, 1152) (136.69 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value of shape (27, 1152, 16, 72) (136.69 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['img']['head']['kernel'].value of shape (1152, 2048) (9.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['llm']['embedder']['input_embedding'].value of shape (257152, 2048) (2009.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.685 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value of shape (18, 8, 256, 2048) (288.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value of shape (18, 8, 256, 1024) (144.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value of shape (18, 2, 1, 2048, 256) (72.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value of shape (18, 2, 1, 1024, 256) (36.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value of shape (18, 8, 2048, 256) (288.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value of shape (18, 8, 1024, 256) (144.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value of shape (18, 2, 2048, 16384) (4608.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp']['linear'].value of shape (18, 16384, 2048) (2304.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value of shape (18, 2, 1024, 4096) (576.00 MiB) along axis 3 (354203:sharding.py:89)
23:55:21.686 [I] Sharding .ema_params['PaliGemma']['llm']['layers']['mlp_1']['linear'].value of shape (18, 4096, 1024) (288.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['action_time_mlp_in']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['action_time_mlp_out']['kernel'].value of shape (1024, 1024) (4.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['mask_decoder']['conv_up_1']['kernel'].value of shape (2, 2, 2048, 512) (16.00 MiB) along axis 2 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.687 [I] Sharding .ema_params['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.688 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.689 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value of shape (1024, 2048) (8.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.690 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value of shape (2048, 1024) (8.00 MiB) along axis 0 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.691 [I] Sharding .ema_params['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value of shape (2048, 2048) (16.00 MiB) along axis 1 (354203:sharding.py:89)
23:55:21.694 [I] Created BasePyTreeCheckpointHandler: pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=None (354203:base_pytree_checkpoint_handler.py:332)
23:55:21.711 [I] Restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (354203:checkpointer.py:256)
23:55:35.420 [I] [process=0] /jax/checkpoint/read/bytes_per_sec: 901.1 MiB/s (total bytes: 12.1 GiB) (time elapsed: 13 seconds) (per-host) (354203:base_pytree_checkpoint_handler.py:113)
23:55:35.420 [I] Finished restoring checkpoint from /home/mbronars/.cache/openpi/openpi-assets/checkpoints/pi0_base/params. (354203:checkpointer.py:259)
23:55:35.420 [I] [process=0][thread=MainThread] Skipping global process sync, barrier name: Checkpointer:restore (354203:multihost.py:293)
23:55:45.002 [I] Initialized train state:
['PaliGemma']['img']['Transformer']['encoder_norm']['bias'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoder_norm']['scale'].value: (1152,)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_0']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['LayerNorm_1']['scale'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['bias'].value: (27, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_0']['kernel'].value: (27, 1152, 4304)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MlpBlock_0']['Dense_1']['kernel'].value: (27, 4304, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['key']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['bias'].value: (27, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['out']['kernel'].value: (27, 16, 72, 1152)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['query']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['bias'].value: (27, 16, 72)@float32
['PaliGemma']['img']['Transformer']['encoderblock']['MultiHeadDotProductAttention_0']['value']['kernel'].value: (27, 1152, 16, 72)@float32
['PaliGemma']['img']['embedding']['bias'].value: (1152,)@float32
['PaliGemma']['img']['embedding']['kernel'].value: (14, 14, 3, 1152)@float32
['PaliGemma']['img']['head']['bias'].value: (2048,)@float32
['PaliGemma']['img']['head']['kernel'].value: (1152, 2048)@float32
['PaliGemma']['img']['pos_embedding'].value: (1, 256, 1152)@float32
['PaliGemma']['llm']['embedder']['input_embedding'].value: (257152, 2048)@float32
['PaliGemma']['llm']['final_norm']['scale'].value: (2048,)@float32
['PaliGemma']['llm']['final_norm_1']['scale'].value: (1024,)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum']['w'].value: (18, 8, 256, 2048)@float32
['PaliGemma']['llm']['layers']['attn']['attn_vec_einsum_1']['w'].value: (18, 8, 256, 1024)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum']['w'].value: (18, 2, 1, 2048, 256)@float32
['PaliGemma']['llm']['layers']['attn']['kv_einsum_1']['w'].value: (18, 2, 1, 1024, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum']['w'].value: (18, 8, 2048, 256)@float32
['PaliGemma']['llm']['layers']['attn']['q_einsum_1']['w'].value: (18, 8, 1024, 256)@float32
['PaliGemma']['llm']['layers']['mlp']['gating_einsum'].value: (18, 2, 2048, 16384)@float32
['PaliGemma']['llm']['layers']['mlp']['linear'].value: (18, 16384, 2048)@float32
['PaliGemma']['llm']['layers']['mlp_1']['gating_einsum'].value: (18, 2, 1024, 4096)@float32
['PaliGemma']['llm']['layers']['mlp_1']['linear'].value: (18, 4096, 1024)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm']['scale'].value: (18, 2048)@float32
['PaliGemma']['llm']['layers']['pre_attention_norm_1']['scale'].value: (18, 1024)@float32
['PaliGemma']['llm']['layers']['pre_ffw_norm']['scale'].value: (18, 2048)@float32
['PaliGemma']['llm']['layers']['pre_ffw_norm_1']['scale'].value: (18, 1024)@float32
['action_in_proj']['bias'].value: (1024,)@float32
['action_in_proj']['kernel'].value: (32, 1024)@float32
['action_out_proj']['bias'].value: (32,)@float32
['action_out_proj']['kernel'].value: (1024, 32)@float32
['action_time_mlp_in']['bias'].value: (1024,)@float32
['action_time_mlp_in']['kernel'].value: (2048, 1024)@float32
['action_time_mlp_out']['bias'].value: (1024,)@float32
['action_time_mlp_out']['kernel'].value: (1024, 1024)@float32
['mask_decoder']['conv_up_1']['bias'].value: (512,)@float32
['mask_decoder']['conv_up_1']['kernel'].value: (2, 2, 2048, 512)@float32
['mask_decoder']['conv_up_2']['bias'].value: (256,)@float32
['mask_decoder']['conv_up_2']['kernel'].value: (2, 2, 512, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_0']['bias'].value: (256,)@float32
['mask_decoder']['iou_head']['layers']['layer_0']['kernel'].value: (2048, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_1']['bias'].value: (256,)@float32
['mask_decoder']['iou_head']['layers']['layer_1']['kernel'].value: (256, 256)@float32
['mask_decoder']['iou_head']['layers']['layer_2']['bias'].value: (2,)@float32
['mask_decoder']['iou_head']['layers']['layer_2']['kernel'].value: (256, 2)@float32
['mask_decoder']['iou_token']['embedding'].value: (1, 2048)@float32
['mask_decoder']['ln_up_1']['bias'].value: (512,)@float32
['mask_decoder']['ln_up_1']['weight'].value: (512,)@float32
['mask_decoder']['mask_tokens']['embedding'].value: (2, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_0']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_2']['bias'].value: (256,)@float32
['mask_decoder']['output_hypernets']['mlp_0']['layers']['layer_2']['kernel'].value: (2048, 256)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_0']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['bias'].value: (2048,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_2']['bias'].value: (256,)@float32
['mask_decoder']['output_hypernets']['mlp_1']['layers']['layer_2']['kernel'].value: (2048, 256)@float32
['mask_decoder']['transformer']['final_attn']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['final_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['final_attn']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['final_attn']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['final_attn']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['final_attn']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_img_to_token']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_0']['cross_token_to_img']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['mlp']['lin2']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm1']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm2']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm3']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm3']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm4']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['norm4']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['k_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['out_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['q_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_0']['self_attn']['v_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_img_to_token']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['k_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['out_proj']['kernel'].value: (1024, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['q_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['bias'].value: (1024,)@float32
['mask_decoder']['transformer']['layers']['block_1']['cross_token_to_img']['v_proj']['kernel'].value: (2048, 1024)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin1']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['mlp']['lin2']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm1']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm1']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm2']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm2']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm3']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm3']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm4']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['norm4']['scale'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['k_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['out_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['q_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['layers']['block_1']['self_attn']['v_proj']['kernel'].value: (2048, 2048)@float32
['mask_decoder']['transformer']['norm_final']['bias'].value: (2048,)@float32
['mask_decoder']['transformer']['norm_final']['scale'].value: (2048,)@float32
['prompt_encoder']['mask_conv1']['bias'].value: (4,)@float32
['prompt_encoder']['mask_conv1']['kernel'].value: (2, 2, 1, 4)@float32
['prompt_encoder']['mask_conv2']['bias'].value: (16,)@float32
['prompt_encoder']['mask_conv2']['kernel'].value: (2, 2, 4, 16)@float32
['prompt_encoder']['mask_conv3']['bias'].value: (2048,)@float32
['prompt_encoder']['mask_conv3']['kernel'].value: (1, 1, 16, 2048)@float32
['prompt_encoder']['mask_ln1']['bias'].value: (4,)@float32
['prompt_encoder']['mask_ln1']['weight'].value: (4,)@float32
['prompt_encoder']['mask_ln2']['bias'].value: (16,)@float32
['prompt_encoder']['mask_ln2']['weight'].value: (16,)@float32
['prompt_encoder']['no_mask_embed']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['not_a_point_embed']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['pe_layer']['gauss'].value: (2, 1024)@float32
['prompt_encoder']['point_embeddings']['point_emb_0']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_1']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_2']['embedding'].value: (1, 2048)@float32
['prompt_encoder']['point_embeddings']['point_emb_3']['embedding'].value: (1, 2048)@float32
['seg_tokens'].value: (1, 3, 2048)@float32
['state_proj']['bias'].value: (1024,)@float32
['state_proj']['kernel'].value: (32, 1024)@float32 (354203:train.py:296)
23:55:45.087 [I] Progress on: -/30000 rate:- remaining:? elapsed:00:00 postfix:-                  (354203:tqdm_logging.py:145)
23:56:02.113 [I] Progress on: -/30000 rate:- remaining:? elapsed:00:17 postfix:-                  (354203:tqdm_logging.py:145)
23:56:02.113 [I] Step 0: grad_norm=69.3177, loss=5.1180, param_norm=1403.1893                     (354203:train.py:326)
23:56:08.008 [I] Step 1: grad_norm=66.6870, loss=5.3468, param_norm=1403.1893                     (354203:train.py:326)
23:56:13.852 [I] Progress on: 2.00it/30.0kit rate:10.5s/it remaining:87:14:41 elapsed:00:28 postfix:- (354203:tqdm_logging.py:145)
23:56:13.853 [I] Step 2: grad_norm=66.7397, loss=5.1331, param_norm=1403.1893                     (354203:train.py:326)
23:56:19.763 [I] Step 3: grad_norm=61.4733, loss=4.8964, param_norm=1403.1893                     (354203:train.py:326)
23:56:25.563 [I] Progress on: 4.00it/30.0kit rate:7.4s/it remaining:61:40:26 elapsed:00:40 postfix:- (354203:tqdm_logging.py:145)
23:56:25.563 [I] Step 4: grad_norm=62.9865, loss=5.0031, param_norm=1403.1893                     (354203:train.py:326)
23:56:31.558 [I] Step 5: grad_norm=59.5828, loss=5.0669, param_norm=1403.1893                     (354203:train.py:326)
23:56:37.520 [I] Progress on: 6.00it/30.0kit rate:6.5s/it remaining:54:23:22 elapsed:00:52 postfix:- (354203:tqdm_logging.py:145)
23:56:37.521 [I] Step 6: grad_norm=57.6918, loss=4.6926, param_norm=1403.1893                     (354203:train.py:326)
23:56:43.534 [I] Step 7: grad_norm=53.4980, loss=4.6283, param_norm=1403.1893                     (354203:train.py:326)
23:56:49.418 [I] Progress on: 8.00it/30.0kit rate:6.2s/it remaining:52:01:01 elapsed:01:04 postfix:- (354203:tqdm_logging.py:145)
23:56:49.419 [I] Step 8: grad_norm=48.4995, loss=4.4415, param_norm=1403.1893                     (354203:train.py:326)
23:56:55.506 [I] Step 9: grad_norm=47.3603, loss=4.2228, param_norm=1403.1893                     (354203:train.py:326)
23:57:01.542 [I] Progress on: 10.0it/30.0kit rate:6.1s/it remaining:50:51:15 elapsed:01:16 postfix:- (354203:tqdm_logging.py:145)
23:57:01.542 [I] Step 10: grad_norm=42.7703, loss=4.3392, param_norm=1403.1893                    (354203:train.py:326)
23:57:07.626 [I] Step 11: grad_norm=40.3599, loss=4.1989, param_norm=1403.1893                    (354203:train.py:326)
23:57:13.704 [I] Progress on: 12.0it/30.0kit rate:6.1s/it remaining:50:43:19 elapsed:01:28 postfix:- (354203:tqdm_logging.py:145)
23:57:13.704 [I] Step 12: grad_norm=37.6753, loss=3.9113, param_norm=1403.1893                    (354203:train.py:326)
23:57:19.836 [I] Step 13: grad_norm=34.8904, loss=3.8901, param_norm=1403.1893                    (354203:train.py:326)
23:57:25.906 [I] Progress on: 14.0it/30.0kit rate:6.1s/it remaining:50:41:47 elapsed:01:40 postfix:- (354203:tqdm_logging.py:145)
23:57:25.907 [I] Step 14: grad_norm=34.1511, loss=3.7607, param_norm=1403.1893                    (354203:train.py:326)
23:57:32.017 [I] Step 15: grad_norm=31.7782, loss=3.6052, param_norm=1403.1893                    (354203:train.py:326)
23:57:38.154 [I] Progress on: 16.0it/30.0kit rate:6.1s/it remaining:50:47:34 elapsed:01:53 postfix:- (354203:tqdm_logging.py:145)
23:57:38.154 [I] Step 16: grad_norm=30.3385, loss=3.5309, param_norm=1403.1893                    (354203:train.py:326)
23:57:45.132 [I] Step 17: grad_norm=29.7373, loss=3.4470, param_norm=1403.1893                    (354203:train.py:326)
23:57:51.249 [I] Progress on: 18.0it/30.0kit rate:6.3s/it remaining:52:20:52 elapsed:02:06 postfix:- (354203:tqdm_logging.py:145)
23:57:51.250 [I] Step 18: grad_norm=28.3970, loss=3.3758, param_norm=1403.1893                    (354203:train.py:326)
23:57:57.415 [I] Step 19: grad_norm=26.3016, loss=3.3546, param_norm=1403.1893                    (354203:train.py:326)
23:58:03.556 [I] Progress on: 20.0it/30.0kit rate:6.2s/it remaining:51:42:49 elapsed:02:18 postfix:- (354203:tqdm_logging.py:145)
23:58:03.557 [I] Step 20: grad_norm=23.8512, loss=3.1763, param_norm=1403.1893                    (354203:train.py:326)
23:58:09.750 [I] Step 21: grad_norm=24.3990, loss=2.9923, param_norm=1403.1893                    (354203:train.py:326)
23:58:15.932 [I] Progress on: 22.0it/30.0kit rate:6.2s/it remaining:51:34:31 elapsed:02:30 postfix:- (354203:tqdm_logging.py:145)
23:58:15.933 [I] Step 22: grad_norm=23.7924, loss=3.0405, param_norm=1403.1893                    (354203:train.py:326)
23:58:22.204 [I] Step 23: grad_norm=27.0857, loss=2.8696, param_norm=1403.1893                    (354203:train.py:326)
23:58:28.369 [I] Progress on: 24.0it/30.0kit rate:6.2s/it remaining:51:38:43 elapsed:02:43 postfix:- (354203:tqdm_logging.py:145)
23:58:28.370 [I] Step 24: grad_norm=21.1825, loss=2.9777, param_norm=1403.1893                    (354203:train.py:326)
23:58:34.576 [I] Step 25: grad_norm=19.4974, loss=2.7523, param_norm=1403.1893                    (354203:train.py:326)
23:58:40.811 [I] Progress on: 26.0it/30.0kit rate:6.2s/it remaining:51:39:19 elapsed:02:55 postfix:- (354203:tqdm_logging.py:145)
23:58:40.812 [I] Step 26: grad_norm=20.8773, loss=2.7186, param_norm=1403.1893                    (354203:train.py:326)
23:58:47.059 [I] Step 27: grad_norm=15.7918, loss=2.5723, param_norm=1403.1893                    (354203:train.py:326)
23:58:53.248 [I] Progress on: 28.0it/30.0kit rate:6.2s/it remaining:51:41:35 elapsed:03:08 postfix:- (354203:tqdm_logging.py:145)
23:58:53.249 [I] Step 28: grad_norm=15.7722, loss=2.4676, param_norm=1403.1893                    (354203:train.py:326)
23:58:59.504 [I] Step 29: grad_norm=16.4618, loss=2.4313, param_norm=1403.1893                    (354203:train.py:326)
23:59:05.739 [I] Progress on: 30.0it/30.0kit rate:6.2s/it remaining:51:46:56 elapsed:03:20 postfix:- (354203:tqdm_logging.py:145)
23:59:05.739 [I] Step 30: grad_norm=15.9287, loss=2.3214, param_norm=1403.1893                    (354203:train.py:326)
23:59:12.010 [I] Step 31: grad_norm=13.0533, loss=2.1854, param_norm=1403.1893                    (354203:train.py:326)
23:59:18.209 [I] Progress on: 32.0it/30.0kit rate:6.2s/it remaining:51:50:19 elapsed:03:33 postfix:- (354203:tqdm_logging.py:145)
23:59:18.209 [I] Step 32: grad_norm=13.6198, loss=2.2163, param_norm=1403.1893                    (354203:train.py:326)
23:59:24.432 [I] Step 33: grad_norm=13.3808, loss=2.1303, param_norm=1403.1893                    (354203:train.py:326)
23:59:31.496 [I] Progress on: 34.0it/30.0kit rate:6.5s/it remaining:53:56:10 elapsed:03:46 postfix:- (354203:tqdm_logging.py:145)
23:59:31.497 [I] Step 34: grad_norm=11.9005, loss=2.0863, param_norm=1403.1892                    (354203:train.py:326)
23:59:37.712 [I] Step 35: grad_norm=11.2997, loss=2.0070, param_norm=1403.1892                    (354203:train.py:326)
23:59:43.931 [I] Progress on: 36.0it/30.0kit rate:6.3s/it remaining:52:50:14 elapsed:03:58 postfix:- (354203:tqdm_logging.py:145)
23:59:43.932 [I] Step 36: grad_norm=10.7691, loss=1.8894, param_norm=1403.1892                    (354203:train.py:326)
23:59:50.143 [I] Step 37: grad_norm=11.1113, loss=1.8240, param_norm=1403.1892                    (354203:train.py:326)
23:59:56.479 [I] Progress on: 38.0it/30.0kit rate:6.3s/it remaining:52:29:29 elapsed:04:11 postfix:- (354203:tqdm_logging.py:145)
23:59:56.480 [I] Step 38: grad_norm=9.7432, loss=1.7199, param_norm=1403.1892                     (354203:train.py:326)
00:00:02.707 [I] Step 39: grad_norm=10.2399, loss=1.6613, param_norm=1403.1893                    (354203:train.py:326)
00:00:08.968 [I] Progress on: 40.0it/30.0kit rate:6.3s/it remaining:52:15:16 elapsed:04:23 postfix:- (354203:tqdm_logging.py:145)
00:00:08.968 [I] Step 40: grad_norm=9.2296, loss=1.6359, param_norm=1403.1893                     (354203:train.py:326)
00:00:15.194 [I] Step 41: grad_norm=9.0677, loss=1.5603, param_norm=1403.1893                     (354203:train.py:326)
00:00:21.382 [I] Progress on: 42.0it/30.0kit rate:6.3s/it remaining:52:18:50 elapsed:04:36 postfix:- (354203:tqdm_logging.py:145)
00:00:21.382 [I] Step 42: grad_norm=8.8542, loss=1.5377, param_norm=1403.1893                     (354203:train.py:326)
00:00:27.608 [I] Step 43: grad_norm=8.5292, loss=1.4584, param_norm=1403.1893                     (354203:train.py:326)
00:00:33.877 [I] Progress on: 44.0it/30.0kit rate:6.2s/it remaining:51:52:48 elapsed:04:48 postfix:- (354203:tqdm_logging.py:145)
00:00:33.878 [I] Step 44: grad_norm=8.1206, loss=1.3491, param_norm=1403.1893                     (354203:train.py:326)
00:00:40.134 [I] Step 45: grad_norm=8.1598, loss=1.3734, param_norm=1403.1893                     (354203:train.py:326)
00:00:46.469 [I] Progress on: 46.0it/30.0kit rate:6.3s/it remaining:52:09:35 elapsed:05:01 postfix:- (354203:tqdm_logging.py:145)
00:00:46.470 [I] Step 46: grad_norm=7.2475, loss=1.2361, param_norm=1403.1893                     (354203:train.py:326)
00:00:52.683 [I] Step 47: grad_norm=7.2908, loss=1.2811, param_norm=1403.1893                     (354203:train.py:326)
00:00:58.961 [I] Progress on: 48.0it/30.0kit rate:6.3s/it remaining:52:04:55 elapsed:05:13 postfix:- (354203:tqdm_logging.py:145)
00:00:58.961 [I] Step 48: grad_norm=6.0164, loss=1.1731, param_norm=1403.1893                     (354203:train.py:326)
00:01:05.194 [I] Step 49: grad_norm=6.6353, loss=1.0767, param_norm=1403.1893                     (354203:train.py:326)
00:01:11.475 [I] Progress on: 50.0it/30.0kit rate:6.3s/it remaining:52:03:23 elapsed:05:26 postfix:- (354203:tqdm_logging.py:145)
00:01:11.476 [I] Step 50: grad_norm=5.4849, loss=1.0590, param_norm=1403.1893                     (354203:train.py:326)
00:01:18.534 [I] Step 51: grad_norm=5.1647, loss=0.9745, param_norm=1403.1893                     (354203:train.py:326)
00:01:24.855 [I] Progress on: 52.0it/30.0kit rate:6.4s/it remaining:53:36:38 elapsed:05:39 postfix:- (354203:tqdm_logging.py:145)
00:01:24.856 [I] Step 52: grad_norm=6.8097, loss=1.0436, param_norm=1403.1893                     (354203:train.py:326)
00:01:31.084 [I] Step 53: grad_norm=6.1255, loss=0.9740, param_norm=1403.1893                     (354203:train.py:326)
00:01:37.329 [I] Progress on: 54.0it/30.0kit rate:6.3s/it remaining:52:42:39 elapsed:05:52 postfix:- (354203:tqdm_logging.py:145)
00:01:37.329 [I] Step 54: grad_norm=5.8646, loss=0.9632, param_norm=1403.1893                     (354203:train.py:326)
00:01:43.612 [I] Step 55: grad_norm=4.0508, loss=0.8863, param_norm=1403.1893                     (354203:train.py:326)
00:01:49.950 [I] Progress on: 56.0it/30.0kit rate:6.3s/it remaining:52:38:09 elapsed:06:04 postfix:- (354203:tqdm_logging.py:145)
00:01:49.951 [I] Step 56: grad_norm=4.9600, loss=0.8777, param_norm=1403.1893                     (354203:train.py:326)
00:01:56.202 [I] Step 57: grad_norm=4.6059, loss=0.8468, param_norm=1403.1893                     (354203:train.py:326)
00:02:02.450 [I] Progress on: 58.0it/30.0kit rate:6.3s/it remaining:52:16:33 elapsed:06:17 postfix:- (354203:tqdm_logging.py:145)
00:02:02.451 [I] Step 58: grad_norm=5.3402, loss=0.8966, param_norm=1403.1893                     (354203:train.py:326)
00:02:08.712 [I] Step 59: grad_norm=5.1451, loss=0.8623, param_norm=1403.1893                     (354203:train.py:326)
00:02:15.282 [I] Progress on: 60.0it/30.0kit rate:6.3s/it remaining:52:19:23 elapsed:06:30 postfix:- (354203:tqdm_logging.py:145)
00:02:15.285 [I] Step 60: grad_norm=4.5969, loss=0.8185, param_norm=1403.1893                     (354203:train.py:326)
00:02:21.513 [I] Step 61: grad_norm=3.6855, loss=0.8164, param_norm=1403.1895                     (354203:train.py:326)
00:02:27.748 [I] Progress on: 62.0it/30.0kit rate:6.3s/it remaining:52:30:39 elapsed:06:42 postfix:- (354203:tqdm_logging.py:145)
00:02:27.749 [I] Step 62: grad_norm=4.0420, loss=0.7662, param_norm=1403.1895                     (354203:train.py:326)
00:02:34.030 [I] Step 63: grad_norm=3.5718, loss=0.7466, param_norm=1403.1895                     (354203:train.py:326)
00:02:40.345 [I] Progress on: 64.0it/30.0kit rate:6.3s/it remaining:52:27:58 elapsed:06:55 postfix:- (354203:tqdm_logging.py:145)
00:02:40.345 [I] Step 64: grad_norm=3.8564, loss=0.7458, param_norm=1403.1893                     (354203:train.py:326)
00:02:46.563 [I] Step 65: grad_norm=2.7720, loss=0.7698, param_norm=1403.1893                     (354203:train.py:326)
00:02:52.809 [I] Progress on: 66.0it/30.0kit rate:6.3s/it remaining:52:05:29 elapsed:07:07 postfix:- (354203:tqdm_logging.py:145)
00:02:52.810 [I] Step 66: grad_norm=6.8570, loss=0.7778, param_norm=1403.1893                     (354203:train.py:326)
00:02:59.066 [I] Step 67: grad_norm=5.2113, loss=0.7562, param_norm=1403.1893                     (354203:train.py:326)
00:03:06.189 [I] Progress on: 68.0it/30.0kit rate:6.5s/it remaining:54:15:54 elapsed:07:21 postfix:- (354203:tqdm_logging.py:145)
00:03:06.190 [I] Step 68: grad_norm=3.3423, loss=0.7629, param_norm=1403.1893                     (354203:train.py:326)
00:03:12.395 [I] Step 69: grad_norm=4.0528, loss=0.7315, param_norm=1403.1893                     (354203:train.py:326)
00:03:18.606 [I] Progress on: 70.0it/30.0kit rate:6.4s/it remaining:52:55:26 elapsed:07:33 postfix:- (354203:tqdm_logging.py:145)
00:03:18.607 [I] Step 70: grad_norm=2.4908, loss=0.7048, param_norm=1403.1893                     (354203:train.py:326)
00:03:24.817 [I] Step 71: grad_norm=3.5340, loss=0.7143, param_norm=1403.1893                     (354203:train.py:326)
00:03:31.148 [I] Progress on: 72.0it/30.0kit rate:6.3s/it remaining:52:28:55 elapsed:07:46 postfix:- (354203:tqdm_logging.py:145)
00:03:31.148 [I] Step 72: grad_norm=3.1420, loss=0.7533, param_norm=1403.1893                     (354203:train.py:326)
00:03:37.387 [I] Step 73: grad_norm=3.3890, loss=0.7275, param_norm=1403.1895                     (354203:train.py:326)
00:03:43.672 [I] Progress on: 74.0it/30.0kit rate:6.3s/it remaining:52:16:11 elapsed:07:58 postfix:- (354203:tqdm_logging.py:145)
00:03:43.672 [I] Step 74: grad_norm=2.6537, loss=0.7235, param_norm=1403.1895                     (354203:train.py:326)
00:03:49.915 [I] Step 75: grad_norm=5.1885, loss=0.7362, param_norm=1403.1895                     (354203:train.py:326)
00:03:56.242 [I] Progress on: 76.0it/30.0kit rate:6.3s/it remaining:52:18:30 elapsed:08:11 postfix:- (354203:tqdm_logging.py:145)
00:03:56.243 [I] Step 76: grad_norm=3.3111, loss=0.7644, param_norm=1403.1895                     (354203:train.py:326)
00:04:02.479 [I] Step 77: grad_norm=3.6651, loss=0.7011, param_norm=1403.1895                     (354203:train.py:326)
00:04:08.746 [I] Progress on: 78.0it/30.0kit rate:6.3s/it remaining:52:08:05 elapsed:08:23 postfix:- (354203:tqdm_logging.py:145)
00:04:08.747 [I] Step 78: grad_norm=3.1946, loss=0.7153, param_norm=1403.1895                     (354203:train.py:326)
00:04:14.986 [I] Step 79: grad_norm=2.1676, loss=0.6702, param_norm=1403.1895                     (354203:train.py:326)
00:04:21.335 [I] Progress on: 80.0it/30.0kit rate:6.3s/it remaining:52:12:47 elapsed:08:36 postfix:- (354203:tqdm_logging.py:145)
00:04:21.336 [I] Step 80: grad_norm=2.4716, loss=0.6906, param_norm=1403.1895                     (354203:train.py:326)
00:04:27.588 [I] Step 81: grad_norm=6.0177, loss=0.6952, param_norm=1403.1895                     (354203:train.py:326)
00:04:33.871 [I] Progress on: 82.0it/30.0kit rate:6.3s/it remaining:52:10:14 elapsed:08:48 postfix:- (354203:tqdm_logging.py:145)
00:04:33.871 [I] Step 82: grad_norm=3.7213, loss=0.7329, param_norm=1403.1895                     (354203:train.py:326)
00:04:40.140 [I] Step 83: grad_norm=4.6360, loss=0.6941, param_norm=1403.1895                     (354203:train.py:326)
00:04:46.441 [I] Progress on: 84.0it/30.0kit rate:6.3s/it remaining:52:11:57 elapsed:09:01 postfix:- (354203:tqdm_logging.py:145)
00:04:46.441 [I] Step 84: grad_norm=6.8556, loss=0.7006, param_norm=1403.1895                     (354203:train.py:326)
00:04:53.506 [I] Step 85: grad_norm=2.8304, loss=0.6861, param_norm=1403.1895                     (354203:train.py:326)
00:04:59.835 [I] Progress on: 86.0it/30.0kit rate:6.5s/it remaining:53:40:52 elapsed:09:14 postfix:- (354203:tqdm_logging.py:145)
00:04:59.835 [I] Step 86: grad_norm=2.5334, loss=0.7017, param_norm=1403.1895                     (354203:train.py:326)
00:05:06.069 [I] Step 87: grad_norm=2.1747, loss=0.6751, param_norm=1403.1895                     (354203:train.py:326)
00:05:12.288 [I] Progress on: 88.0it/30.0kit rate:6.4s/it remaining:52:45:48 elapsed:09:27 postfix:- (354203:tqdm_logging.py:145)
00:05:12.288 [I] Step 88: grad_norm=2.0325, loss=0.6693, param_norm=1403.1895                     (354203:train.py:326)
00:05:18.585 [I] Step 89: grad_norm=1.8803, loss=0.6677, param_norm=1403.1895                     (354203:train.py:326)
00:05:24.896 [I] Progress on: 90.0it/30.0kit rate:6.3s/it remaining:52:29:54 elapsed:09:39 postfix:- (354203:tqdm_logging.py:145)
00:05:24.896 [I] Step 90: grad_norm=2.8516, loss=0.6697, param_norm=1403.1895                     (354203:train.py:326)
00:05:31.125 [I] Step 91: grad_norm=2.7153, loss=0.6762, param_norm=1403.1895                     (354203:train.py:326)
00:05:37.352 [I] Progress on: 92.0it/30.0kit rate:6.3s/it remaining:52:08:54 elapsed:09:52 postfix:- (354203:tqdm_logging.py:145)
00:05:37.353 [I] Step 92: grad_norm=2.7001, loss=0.6674, param_norm=1403.1895                     (354203:train.py:326)
00:05:43.669 [I] Step 93: grad_norm=4.7720, loss=0.6808, param_norm=1403.1895                     (354203:train.py:326)
00:05:49.975 [I] Progress on: 94.0it/30.0kit rate:6.3s/it remaining:52:15:32 elapsed:10:04 postfix:- (354203:tqdm_logging.py:145)
00:05:49.976 [I] Step 94: grad_norm=2.0561, loss=0.6745, param_norm=1403.1895                     (354203:train.py:326)
00:05:56.213 [I] Step 95: grad_norm=4.1220, loss=0.6757, param_norm=1403.1895                     (354203:train.py:326)
00:06:02.473 [I] Progress on: 96.0it/30.0kit rate:6.3s/it remaining:52:02:04 elapsed:10:17 postfix:- (354203:tqdm_logging.py:145)
00:06:02.474 [I] Step 96: grad_norm=2.4488, loss=0.6638, param_norm=1403.1895                     (354203:train.py:326)
00:06:08.782 [I] Step 97: grad_norm=4.5512, loss=0.6935, param_norm=1403.1895                     (354203:train.py:326)
00:06:15.087 [I] Progress on: 98.0it/30.0kit rate:6.3s/it remaining:52:14:25 elapsed:10:30 postfix:- (354203:tqdm_logging.py:145)
00:06:15.088 [I] Step 98: grad_norm=4.0169, loss=0.7172, param_norm=1403.1895                     (354203:train.py:326)
00:06:21.336 [I] Step 99: grad_norm=5.5753, loss=0.6648, param_norm=1403.1895                     (354203:train.py:326)
00:06:27.576 [I] Progress on: 100it/30.0kit rate:6.3s/it remaining:52:03:15 elapsed:10:42 postfix:- (354203:tqdm_logging.py:145)
00:06:27.576 [I] Step 100: grad_norm=2.5379, loss=0.6561, param_norm=1403.1895                    (354203:train.py:326)
00:06:33.853 [I] Step 101: grad_norm=3.7860, loss=0.6841, param_norm=1403.1896                    (354203:train.py:326)
00:06:40.918 [I] Progress on: 102it/30.0kit rate:6.5s/it remaining:54:07:40 elapsed:10:55 postfix:- (354203:tqdm_logging.py:145)
00:06:40.919 [I] Step 102: grad_norm=2.5360, loss=0.6468, param_norm=1403.1895                    (354203:train.py:326)
00:06:47.149 [I] Step 103: grad_norm=2.2181, loss=0.6625, param_norm=1403.1896                    (354203:train.py:326)
00:06:53.386 [I] Progress on: 104it/30.0kit rate:6.4s/it remaining:52:52:31 elapsed:11:08 postfix:- (354203:tqdm_logging.py:145)
00:06:53.387 [I] Step 104: grad_norm=1.9009, loss=0.6606, param_norm=1403.1896                    (354203:train.py:326)
00:06:59.646 [I] Step 105: grad_norm=1.9485, loss=0.6450, param_norm=1403.1896                    (354203:train.py:326)
00:07:05.923 [I] Progress on: 106it/30.0kit rate:6.3s/it remaining:52:31:13 elapsed:11:20 postfix:- (354203:tqdm_logging.py:145)
00:07:05.924 [I] Step 106: grad_norm=9.9333, loss=0.6520, param_norm=1403.1896                    (354203:train.py:326)
00:07:12.177 [I] Step 107: grad_norm=2.1409, loss=0.6628, param_norm=1403.1896                    (354203:train.py:326)
00:07:18.416 [I] Progress on: 108it/30.0kit rate:6.3s/it remaining:52:06:47 elapsed:11:33 postfix:- (354203:tqdm_logging.py:145)
00:07:18.417 [I] Step 108: grad_norm=10.0339, loss=0.7005, param_norm=1403.1895                   (354203:train.py:326)
00:07:24.667 [I] Step 109: grad_norm=3.2323, loss=0.6574, param_norm=1403.1895                    (354203:train.py:326)
00:07:30.934 [I] Progress on: 110it/30.0kit rate:6.3s/it remaining:52:05:11 elapsed:11:45 postfix:- (354203:tqdm_logging.py:145)
00:07:30.935 [I] Step 110: grad_norm=1.8730, loss=0.6469, param_norm=1403.1896                    (354203:train.py:326)
00:07:37.187 [I] Step 111: grad_norm=4.5137, loss=0.6695, param_norm=1403.1896                    (354203:train.py:326)
00:07:43.429 [I] Progress on: 112it/30.0kit rate:6.3s/it remaining:51:54:29 elapsed:11:58 postfix:- (354203:tqdm_logging.py:145)
00:07:43.429 [I] Step 112: grad_norm=2.3051, loss=0.6513, param_norm=1403.1896                    (354203:train.py:326)
00:07:49.705 [I] Step 113: grad_norm=3.6394, loss=0.6642, param_norm=1403.1896                    (354203:train.py:326)
00:07:56.002 [I] Progress on: 114it/30.0kit rate:6.3s/it remaining:52:02:57 elapsed:12:10 postfix:- (354203:tqdm_logging.py:145)
00:07:56.003 [I] Step 114: grad_norm=3.7229, loss=0.6848, param_norm=1403.1896                    (354203:train.py:326)
00:08:02.256 [I] Step 115: grad_norm=1.3363, loss=0.6309, param_norm=1403.1896                    (354203:train.py:326)
00:08:08.481 [I] Progress on: 116it/30.0kit rate:6.3s/it remaining:51:56:43 elapsed:12:23 postfix:- (354203:tqdm_logging.py:145)
00:08:08.481 [I] Step 116: grad_norm=1.9583, loss=0.6437, param_norm=1403.1896                    (354203:train.py:326)
00:08:14.754 [I] Step 117: grad_norm=2.2739, loss=0.6374, param_norm=1403.1896                    (354203:train.py:326)
00:08:21.038 [I] Progress on: 118it/30.0kit rate:6.3s/it remaining:51:57:55 elapsed:12:35 postfix:- (354203:tqdm_logging.py:145)
00:08:21.039 [I] Step 118: grad_norm=2.0372, loss=0.6688, param_norm=1403.1896                    (354203:train.py:326)
00:08:28.066 [I] Step 119: grad_norm=2.9813, loss=0.6915, param_norm=1403.1896                    (354203:train.py:326)
00:08:34.343 [I] Progress on: 120it/30.0kit rate:6.4s/it remaining:53:23:13 elapsed:12:49 postfix:- (354203:tqdm_logging.py:145)
00:08:34.343 [I] Step 120: grad_norm=2.0519, loss=0.6289, param_norm=1403.1896                    (354203:train.py:326)
00:08:40.586 [I] Step 121: grad_norm=2.0924, loss=0.6486, param_norm=1403.1896                    (354203:train.py:326)
00:08:46.859 [I] Progress on: 122it/30.0kit rate:6.3s/it remaining:52:38:47 elapsed:13:01 postfix:- (354203:tqdm_logging.py:145)
00:08:46.860 [I] Step 122: grad_norm=2.3395, loss=0.6248, param_norm=1403.1896                    (354203:train.py:326)
00:08:53.130 [I] Step 123: grad_norm=1.5213, loss=0.6408, param_norm=1403.1896                    (354203:train.py:326)
00:08:59.409 [I] Progress on: 124it/30.0kit rate:6.3s/it remaining:52:22:43 elapsed:13:14 postfix:- (354203:tqdm_logging.py:145)
00:08:59.410 [I] Step 124: grad_norm=2.7610, loss=0.6361, param_norm=1403.1896                    (354203:train.py:326)
00:09:05.656 [I] Step 125: grad_norm=1.5413, loss=0.6221, param_norm=1403.1896                    (354203:train.py:326)
00:09:11.924 [I] Progress on: 126it/30.0kit rate:6.3s/it remaining:52:07:39 elapsed:13:26 postfix:- (354203:tqdm_logging.py:145)
00:09:11.925 [I] Step 126: grad_norm=2.6422, loss=0.6314, param_norm=1403.1897                    (354203:train.py:326)
00:09:18.202 [I] Step 127: grad_norm=2.4302, loss=0.6485, param_norm=1403.1897                    (354203:train.py:326)
00:09:24.487 [I] Progress on: 128it/30.0kit rate:6.3s/it remaining:52:09:06 elapsed:13:39 postfix:- (354203:tqdm_logging.py:145)
00:09:24.488 [I] Step 128: grad_norm=1.6617, loss=0.6304, param_norm=1403.1897                    (354203:train.py:326)
00:09:30.712 [I] Step 129: grad_norm=1.5030, loss=0.6249, param_norm=1403.1897                    (354203:train.py:326)
00:09:36.823 [I] Progress on: 130it/30.0kit rate:6.3s/it remaining:51:57:57 elapsed:13:51 postfix:- (354203:tqdm_logging.py:145)
00:09:36.824 [I] Step 130: grad_norm=2.6677, loss=0.6302, param_norm=1403.1897                    (354203:train.py:326)
00:09:43.075 [I] Step 131: grad_norm=2.6892, loss=0.6574, param_norm=1403.1897                    (354203:train.py:326)
00:09:49.371 [I] Progress on: 132it/30.0kit rate:6.2s/it remaining:51:43:46 elapsed:14:04 postfix:- (354203:tqdm_logging.py:145)
00:09:49.372 [I] Step 132: grad_norm=1.4326, loss=0.6236, param_norm=1403.1897                    (354203:train.py:326)
00:09:55.633 [I] Step 133: grad_norm=2.6523, loss=0.6255, param_norm=1403.1897                    (354203:train.py:326)
00:10:01.924 [I] Progress on: 134it/30.0kit rate:6.3s/it remaining:51:53:20 elapsed:14:16 postfix:- (354203:tqdm_logging.py:145)
00:10:01.925 [I] Step 134: grad_norm=1.5950, loss=0.6347, param_norm=1403.1897                    (354203:train.py:326)
00:10:08.214 [I] Step 135: grad_norm=1.1948, loss=0.6142, param_norm=1403.1897                    (354203:train.py:326)
00:10:15.297 [I] Progress on: 136it/30.0kit rate:6.5s/it remaining:54:05:36 elapsed:14:30 postfix:- (354203:tqdm_logging.py:145)
00:10:15.298 [I] Step 136: grad_norm=1.7055, loss=0.6260, param_norm=1403.1897                    (354203:train.py:326)
00:10:21.539 [I] Step 137: grad_norm=1.3664, loss=0.6261, param_norm=1403.1897                    (354203:train.py:326)
00:10:27.794 [I] Progress on: 138it/30.0kit rate:6.4s/it remaining:52:57:23 elapsed:14:42 postfix:- (354203:tqdm_logging.py:145)
00:10:27.794 [I] Step 138: grad_norm=2.1488, loss=0.6301, param_norm=1403.1897                    (354203:train.py:326)
00:10:34.035 [I] Step 139: grad_norm=1.8297, loss=0.6310, param_norm=1403.1897                    (354203:train.py:326)
00:10:40.356 [I] Progress on: 140it/30.0kit rate:6.3s/it remaining:52:31:42 elapsed:14:55 postfix:- (354203:tqdm_logging.py:145)
00:10:40.356 [I] Step 140: grad_norm=2.2014, loss=0.6239, param_norm=1403.1897                    (354203:train.py:326)
00:10:46.633 [I] Step 141: grad_norm=1.3769, loss=0.6678, param_norm=1403.1897                    (354203:train.py:326)
00:10:52.920 [I] Progress on: 142it/30.0kit rate:6.3s/it remaining:52:16:35 elapsed:15:07 postfix:- (354203:tqdm_logging.py:145)
00:10:52.920 [I] Step 142: grad_norm=1.8873, loss=0.6578, param_norm=1403.1897                    (354203:train.py:326)
00:10:59.170 [I] Step 143: grad_norm=2.2264, loss=0.6403, param_norm=1403.1897                    (354203:train.py:326)
00:11:05.480 [I] Progress on: 144it/30.0kit rate:6.3s/it remaining:52:12:55 elapsed:15:20 postfix:- (354203:tqdm_logging.py:145)
00:11:05.480 [I] Step 144: grad_norm=1.9857, loss=0.6240, param_norm=1403.1897                    (354203:train.py:326)
00:11:11.737 [I] Step 145: grad_norm=2.4242, loss=0.6476, param_norm=1403.1897                    (354203:train.py:326)
00:11:18.022 [I] Progress on: 146it/30.0kit rate:6.3s/it remaining:52:05:15 elapsed:15:32 postfix:- (354203:tqdm_logging.py:145)
00:11:18.023 [I] Step 146: grad_norm=1.5284, loss=0.6158, param_norm=1403.1897                    (354203:train.py:326)
00:11:24.264 [I] Step 147: grad_norm=1.3393, loss=0.6201, param_norm=1403.1897                    (354203:train.py:326)
00:11:30.556 [I] Progress on: 148it/30.0kit rate:6.3s/it remaining:52:05:41 elapsed:15:45 postfix:- (354203:tqdm_logging.py:145)
00:11:30.557 [I] Step 148: grad_norm=0.9729, loss=0.6142, param_norm=1403.1897                    (354203:train.py:326)
00:11:36.832 [I] Step 149: grad_norm=1.7896, loss=0.6186, param_norm=1403.1897                    (354203:train.py:326)
00:11:43.126 [I] Progress on: 150it/30.0kit rate:6.3s/it remaining:52:02:14 elapsed:15:58 postfix:- (354203:tqdm_logging.py:145)
00:11:43.126 [I] Step 150: grad_norm=1.5067, loss=0.6305, param_norm=1403.1898                    (354203:train.py:326)
00:11:49.383 [I] Step 151: grad_norm=1.2495, loss=0.6157, param_norm=1403.1898                    (354203:train.py:326)
00:11:55.658 [I] Progress on: 152it/30.0kit rate:6.3s/it remaining:52:01:47 elapsed:16:10 postfix:- (354203:tqdm_logging.py:145)
00:11:55.659 [I] Step 152: grad_norm=2.1059, loss=0.6279, param_norm=1403.1898                    (354203:train.py:326)
00:12:02.770 [I] Step 153: grad_norm=4.2412, loss=0.6409, param_norm=1403.1897                    (354203:train.py:326)
00:12:09.019 [I] Progress on: 154it/30.0kit rate:6.4s/it remaining:53:24:20 elapsed:16:23 postfix:- (354203:tqdm_logging.py:145)
00:12:09.020 [I] Step 154: grad_norm=2.0692, loss=0.6471, param_norm=1403.1898                    (354203:train.py:326)
00:12:15.269 [I] Step 155: grad_norm=2.0820, loss=0.6488, param_norm=1403.1898                    (354203:train.py:326)
00:12:21.524 [I] Progress on: 156it/30.0kit rate:6.3s/it remaining:52:35:09 elapsed:16:36 postfix:- (354203:tqdm_logging.py:145)
00:12:21.524 [I] Step 156: grad_norm=1.4929, loss=0.6209, param_norm=1403.1898                    (354203:train.py:326)
00:12:27.860 [I] Step 157: grad_norm=2.7424, loss=0.6284, param_norm=1403.1897                    (354203:train.py:326)
00:12:34.099 [I] Progress on: 158it/30.0kit rate:6.3s/it remaining:52:20:33 elapsed:16:49 postfix:- (354203:tqdm_logging.py:145)
00:12:34.100 [I] Step 158: grad_norm=1.7699, loss=0.6297, param_norm=1403.1898                    (354203:train.py:326)
00:12:40.389 [I] Step 159: grad_norm=2.6927, loss=0.6586, param_norm=1403.1897                    (354203:train.py:326)
00:12:46.639 [I] Progress on: 160it/30.0kit rate:6.3s/it remaining:52:07:11 elapsed:17:01 postfix:- (354203:tqdm_logging.py:145)
00:12:46.639 [I] Step 160: grad_norm=2.4172, loss=0.6119, param_norm=1403.1897                    (354203:train.py:326)
00:12:52.974 [I] Step 161: grad_norm=2.8736, loss=0.6206, param_norm=1403.1898                    (354203:train.py:326)
00:12:59.230 [I] Progress on: 162it/30.0kit rate:6.3s/it remaining:52:06:04 elapsed:17:14 postfix:- (354203:tqdm_logging.py:145)
00:12:59.230 [I] Step 162: grad_norm=3.0945, loss=0.6271, param_norm=1403.1898                    (354203:train.py:326)
00:13:05.511 [I] Step 163: grad_norm=1.6258, loss=0.6394, param_norm=1403.1897                    (354203:train.py:326)
00:13:11.768 [I] Progress on: 164it/30.0kit rate:6.3s/it remaining:52:00:33 elapsed:17:26 postfix:- (354203:tqdm_logging.py:145)
00:13:11.768 [I] Step 164: grad_norm=6.6128, loss=0.6521, param_norm=1403.1898                    (354203:train.py:326)
00:13:18.099 [I] Step 165: grad_norm=2.1952, loss=0.6086, param_norm=1403.1898                    (354203:train.py:326)
00:13:24.352 [I] Progress on: 166it/30.0kit rate:6.3s/it remaining:52:02:53 elapsed:17:39 postfix:- (354203:tqdm_logging.py:145)
00:13:24.352 [I] Step 166: grad_norm=1.5204, loss=0.6085, param_norm=1403.1898                    (354203:train.py:326)
00:13:30.594 [I] Step 167: grad_norm=1.4726, loss=0.6089, param_norm=1403.1898                    (354203:train.py:326)
00:13:36.827 [I] Progress on: 168it/30.0kit rate:6.3s/it remaining:51:52:55 elapsed:17:51 postfix:- (354203:tqdm_logging.py:145)
00:13:36.827 [I] Step 168: grad_norm=2.0725, loss=0.6243, param_norm=1403.1898                    (354203:train.py:326)
00:13:43.099 [I] Step 169: grad_norm=2.1634, loss=0.6214, param_norm=1403.1898                    (354203:train.py:326)
00:13:50.141 [I] Progress on: 170it/30.0kit rate:6.5s/it remaining:53:49:58 elapsed:18:05 postfix:- (354203:tqdm_logging.py:145)
00:13:50.142 [I] Step 170: grad_norm=2.2229, loss=0.6180, param_norm=1403.1899                    (354203:train.py:326)
00:13:56.494 [I] Step 171: grad_norm=2.3658, loss=0.6108, param_norm=1403.1898                    (354203:train.py:326)
00:14:02.730 [I] Progress on: 172it/30.0kit rate:6.4s/it remaining:52:56:39 elapsed:18:17 postfix:- (354203:tqdm_logging.py:145)
00:14:02.730 [I] Step 172: grad_norm=1.8618, loss=0.6319, param_norm=1403.1898                    (354203:train.py:326)
00:14:08.968 [I] Step 173: grad_norm=1.6124, loss=0.6542, param_norm=1403.1898                    (354203:train.py:326)
00:14:15.209 [I] Progress on: 174it/30.0kit rate:6.3s/it remaining:52:22:55 elapsed:18:30 postfix:- (354203:tqdm_logging.py:145)
00:14:15.209 [I] Step 174: grad_norm=1.2763, loss=0.6092, param_norm=1403.1899                    (354203:train.py:326)
00:14:21.552 [I] Step 175: grad_norm=5.0553, loss=0.6299, param_norm=1403.1899                    (354203:train.py:326)
00:14:27.802 [I] Progress on: 176it/30.0kit rate:6.3s/it remaining:52:08:52 elapsed:18:42 postfix:- (354203:tqdm_logging.py:145)
00:14:27.803 [I] Step 176: grad_norm=2.9060, loss=0.6302, param_norm=1403.1899                    (354203:train.py:326)
00:14:34.061 [I] Step 177: grad_norm=1.4252, loss=0.6237, param_norm=1403.1899                    (354203:train.py:326)
00:14:40.357 [I] Progress on: 178it/30.0kit rate:6.3s/it remaining:52:04:34 elapsed:18:55 postfix:- (354203:tqdm_logging.py:145)
00:14:40.358 [I] Step 178: grad_norm=2.0436, loss=0.6472, param_norm=1403.1899                    (354203:train.py:326)
00:14:46.710 [I] Step 179: grad_norm=1.5936, loss=0.6166, param_norm=1403.1899                    (354203:train.py:326)
00:14:52.956 [I] Progress on: 180it/30.0kit rate:6.3s/it remaining:52:06:38 elapsed:19:07 postfix:- (354203:tqdm_logging.py:145)
00:14:52.956 [I] Step 180: grad_norm=1.3967, loss=0.6054, param_norm=1403.1899                    (354203:train.py:326)
00:14:59.212 [I] Step 181: grad_norm=2.1506, loss=0.6375, param_norm=1403.1899                    (354203:train.py:326)
00:15:05.492 [I] Progress on: 182it/30.0kit rate:6.3s/it remaining:52:02:12 elapsed:19:20 postfix:- (354203:tqdm_logging.py:145)
00:15:05.493 [I] Step 182: grad_norm=2.3444, loss=0.6199, param_norm=1403.1899                    (354203:train.py:326)
00:15:11.837 [I] Step 183: grad_norm=1.0031, loss=0.6408, param_norm=1403.1899                    (354203:train.py:326)
00:15:18.083 [I] Progress on: 184it/30.0kit rate:6.3s/it remaining:52:02:51 elapsed:19:32 postfix:- (354203:tqdm_logging.py:145)
00:15:18.084 [I] Step 184: grad_norm=1.6828, loss=0.6188, param_norm=1403.1899                    (354203:train.py:326)
00:15:24.323 [I] Step 185: grad_norm=1.9955, loss=0.6242, param_norm=1403.1898                    (354203:train.py:326)
00:15:30.600 [I] Progress on: 186it/30.0kit rate:6.3s/it remaining:51:57:33 elapsed:19:45 postfix:- (354203:tqdm_logging.py:145)
00:15:30.601 [I] Step 186: grad_norm=1.5575, loss=0.6107, param_norm=1403.1898                    (354203:train.py:326)
00:15:37.714 [I] Step 187: grad_norm=1.1512, loss=0.6119, param_norm=1403.1898                    (354203:train.py:326)
00:15:43.937 [I] Progress on: 188it/30.0kit rate:6.4s/it remaining:53:19:08 elapsed:19:58 postfix:- (354203:tqdm_logging.py:145)
00:15:43.937 [I] Step 188: grad_norm=2.3695, loss=0.6164, param_norm=1403.1898                    (354203:train.py:326)
00:15:50.176 [I] Step 189: grad_norm=1.3390, loss=0.6145, param_norm=1403.1898                    (354203:train.py:326)
00:15:56.424 [I] Progress on: 190it/30.0kit rate:6.3s/it remaining:52:26:46 elapsed:20:11 postfix:- (354203:tqdm_logging.py:145)
00:15:56.425 [I] Step 190: grad_norm=3.6603, loss=0.6354, param_norm=1403.1898                    (354203:train.py:326)
00:16:02.785 [I] Step 191: grad_norm=1.0259, loss=0.5941, param_norm=1403.1898                    (354203:train.py:326)
00:16:09.047 [I] Progress on: 192it/30.0kit rate:6.3s/it remaining:52:16:55 elapsed:20:23 postfix:- (354203:tqdm_logging.py:145)
00:16:09.048 [I] Step 192: grad_norm=4.6289, loss=0.6282, param_norm=1403.1898                    (354203:train.py:326)
00:16:15.305 [I] Step 193: grad_norm=5.0079, loss=0.6284, param_norm=1403.1898                    (354203:train.py:326)
00:16:21.558 [I] Progress on: 194it/30.0kit rate:6.3s/it remaining:52:02:38 elapsed:20:36 postfix:- (354203:tqdm_logging.py:145)
00:16:21.558 [I] Step 194: grad_norm=2.1434, loss=0.6176, param_norm=1403.1898                    (354203:train.py:326)
00:16:27.929 [I] Step 195: grad_norm=2.8777, loss=0.6253, param_norm=1403.1898                    (354203:train.py:326)
00:16:34.178 [I] Progress on: 196it/30.0kit rate:6.3s/it remaining:52:05:57 elapsed:20:49 postfix:- (354203:tqdm_logging.py:145)
00:16:34.178 [I] Step 196: grad_norm=0.7868, loss=0.6108, param_norm=1403.1898                    (354203:train.py:326)
00:16:40.424 [I] Step 197: grad_norm=2.6921, loss=0.6198, param_norm=1403.1898                    (354203:train.py:326)
00:16:46.672 [I] Progress on: 198it/30.0kit rate:6.3s/it remaining:51:54:00 elapsed:21:01 postfix:- (354203:tqdm_logging.py:145)
00:16:46.672 [I] Step 198: grad_norm=1.3473, loss=0.6115, param_norm=1403.1898                    (354203:train.py:326)
00:16:53.014 [I] Step 199: grad_norm=2.0347, loss=0.6128, param_norm=1403.1898                    (354203:train.py:326)
00:16:59.286 [I] Progress on: 200it/30.0kit rate:6.3s/it remaining:51:58:21 elapsed:21:14 postfix:- (354203:tqdm_logging.py:145)
00:16:59.286 [I] Step 200: grad_norm=2.4184, loss=0.6072, param_norm=1403.1898                    (354203:train.py:326)
00:17:05.567 [I] Step 201: grad_norm=1.2106, loss=0.6218, param_norm=1403.1898                    (354203:train.py:326)
00:17:11.828 [I] Progress on: 202it/30.0kit rate:6.3s/it remaining:51:58:03 elapsed:21:26 postfix:- (354203:tqdm_logging.py:145)
00:17:11.828 [I] Step 202: grad_norm=1.7936, loss=0.6326, param_norm=1403.1899                    (354203:train.py:326)
00:17:18.105 [I] Step 203: grad_norm=1.7229, loss=0.6473, param_norm=1403.1899                    (354203:train.py:326)
00:17:25.629 [I] Progress on: 204it/30.0kit rate:6.5s/it remaining:53:53:02 elapsed:21:40 postfix:- (354203:tqdm_logging.py:145)
00:17:25.629 [I] Step 204: grad_norm=1.0408, loss=0.6051, param_norm=1403.1899                    (354203:train.py:326)
00:17:31.916 [I] Step 205: grad_norm=0.9079, loss=0.5983, param_norm=1403.1899                    (354203:train.py:326)
00:17:38.164 [I] Progress on: 206it/30.0kit rate:6.5s/it remaining:53:42:54 elapsed:21:53 postfix:- (354203:tqdm_logging.py:145)
00:17:38.164 [I] Step 206: grad_norm=2.2663, loss=0.6089, param_norm=1403.1899                    (354203:train.py:326)
00:17:44.372 [I] Step 207: grad_norm=3.0766, loss=0.6746, param_norm=1403.1899                    (354203:train.py:326)
00:17:50.638 [I] Progress on: 208it/30.0kit rate:6.4s/it remaining:52:35:32 elapsed:22:05 postfix:- (354203:tqdm_logging.py:145)
00:17:50.638 [I] Step 208: grad_norm=1.8448, loss=0.6459, param_norm=1403.1899                    (354203:train.py:326)
00:17:56.953 [I] Step 209: grad_norm=3.4213, loss=0.5883, param_norm=1403.1899                    (354203:train.py:326)
00:18:03.247 [I] Progress on: 210it/30.0kit rate:6.3s/it remaining:52:20:32 elapsed:22:18 postfix:- (354203:tqdm_logging.py:145)
00:18:03.247 [I] Step 210: grad_norm=3.8083, loss=0.6091, param_norm=1403.1899                    (354203:train.py:326)
00:18:09.480 [I] Step 211: grad_norm=4.1509, loss=0.6067, param_norm=1403.1899                    (354203:train.py:326)
00:18:15.763 [I] Progress on: 212it/30.0kit rate:6.3s/it remaining:52:02:47 elapsed:22:30 postfix:- (354203:tqdm_logging.py:145)
00:18:15.763 [I] Step 212: grad_norm=4.6331, loss=0.6245, param_norm=1403.1901                    (354203:train.py:326)
00:18:22.091 [I] Step 213: grad_norm=2.5492, loss=0.6061, param_norm=1403.1901                    (354203:train.py:326)
00:18:28.371 [I] Progress on: 214it/30.0kit rate:6.3s/it remaining:52:06:32 elapsed:22:43 postfix:- (354203:tqdm_logging.py:145)
00:18:28.372 [I] Step 214: grad_norm=3.5490, loss=0.6114, param_norm=1403.1901                    (354203:train.py:326)
00:18:34.603 [I] Step 215: grad_norm=2.7240, loss=0.6043, param_norm=1403.1901                    (354203:train.py:326)
00:18:40.871 [I] Progress on: 216it/30.0kit rate:6.3s/it remaining:51:55:41 elapsed:22:55 postfix:- (354203:tqdm_logging.py:145)
00:18:40.871 [I] Step 216: grad_norm=1.4298, loss=0.6022, param_norm=1403.1901                    (354203:train.py:326)
00:18:47.175 [I] Step 217: grad_norm=3.8727, loss=0.6011, param_norm=1403.1901                    (354203:train.py:326)
00:18:53.434 [I] Progress on: 218it/30.0kit rate:6.3s/it remaining:51:57:10 elapsed:23:08 postfix:- (354203:tqdm_logging.py:145)
00:18:53.434 [I] Step 218: grad_norm=1.8516, loss=0.5949, param_norm=1403.1901                    (354203:train.py:326)
00:18:59.672 [I] Step 219: grad_norm=6.4768, loss=0.5933, param_norm=1403.1901                    (354203:train.py:326)
00:19:05.919 [I] Progress on: 220it/30.0kit rate:6.3s/it remaining:51:49:43 elapsed:23:20 postfix:- (354203:tqdm_logging.py:145)
00:19:05.919 [I] Step 220: grad_norm=4.7079, loss=0.5831, param_norm=1403.1901                    (354203:train.py:326)
00:19:12.951 [I] Step 221: grad_norm=3.7236, loss=0.5947, param_norm=1403.1902                    (354203:train.py:326)
00:19:19.212 [I] Progress on: 222it/30.0kit rate:6.4s/it remaining:53:08:11 elapsed:23:34 postfix:- (354203:tqdm_logging.py:145)
00:19:19.213 [I] Step 222: grad_norm=4.3615, loss=0.6145, param_norm=1403.1902                    (354203:train.py:326)
00:19:25.510 [I] Step 223: grad_norm=2.8459, loss=0.5980, param_norm=1403.1902                    (354203:train.py:326)
00:19:31.746 [I] Progress on: 224it/30.0kit rate:6.3s/it remaining:52:26:17 elapsed:23:46 postfix:- (354203:tqdm_logging.py:145)
00:19:31.747 [I] Step 224: grad_norm=3.6177, loss=0.5895, param_norm=1403.1903                    (354203:train.py:326)
00:19:38.013 [I] Step 225: grad_norm=3.3995, loss=0.5878, param_norm=1403.1903                    (354203:train.py:326)
00:19:44.317 [I] Progress on: 226it/30.0kit rate:6.3s/it remaining:52:10:46 elapsed:23:59 postfix:- (354203:tqdm_logging.py:145)
00:19:44.317 [I] Step 226: grad_norm=2.0108, loss=0.5695, param_norm=1403.1903                    (354203:train.py:326)
00:19:50.621 [I] Step 227: grad_norm=7.2320, loss=0.5807, param_norm=1403.1903                    (354203:train.py:326)
00:19:56.859 [I] Progress on: 228it/30.0kit rate:6.3s/it remaining:52:00:59 elapsed:24:11 postfix:- (354203:tqdm_logging.py:145)
00:19:56.860 [I] Step 228: grad_norm=5.0504, loss=0.5788, param_norm=1403.1903                    (354203:train.py:326)
00:20:03.138 [I] Step 229: grad_norm=5.4149, loss=0.5945, param_norm=1403.1903                    (354203:train.py:326)
00:20:09.416 [I] Progress on: 230it/30.0kit rate:6.3s/it remaining:51:55:12 elapsed:24:24 postfix:- (354203:tqdm_logging.py:145)
00:20:09.416 [I] Step 230: grad_norm=5.5495, loss=0.5729, param_norm=1403.1903                    (354203:train.py:326)
00:20:15.725 [I] Step 231: grad_norm=3.3041, loss=0.5824, param_norm=1403.1903                    (354203:train.py:326)
00:20:21.962 [I] Progress on: 232it/30.0kit rate:6.3s/it remaining:51:54:27 elapsed:24:36 postfix:- (354203:tqdm_logging.py:145)
00:20:21.963 [I] Step 232: grad_norm=3.4061, loss=0.5644, param_norm=1403.1903                    (354203:train.py:326)
00:20:28.239 [I] Step 233: grad_norm=6.5672, loss=0.5836, param_norm=1403.1903                    (354203:train.py:326)
00:20:34.514 [I] Progress on: 234it/30.0kit rate:6.3s/it remaining:51:52:25 elapsed:24:49 postfix:- (354203:tqdm_logging.py:145)
00:20:34.514 [I] Step 234: grad_norm=4.9998, loss=0.5746, param_norm=1403.1903                    (354203:train.py:326)
00:20:40.803 [I] Step 235: grad_norm=6.1868, loss=0.5643, param_norm=1403.1903                    (354203:train.py:326)
00:20:47.040 [I] Progress on: 236it/30.0kit rate:6.3s/it remaining:51:49:15 elapsed:25:01 postfix:- (354203:tqdm_logging.py:145)
00:20:47.041 [I] Step 236: grad_norm=5.3603, loss=0.5579, param_norm=1403.1903                    (354203:train.py:326)
00:20:53.319 [I] Step 237: grad_norm=4.6628, loss=0.5604, param_norm=1403.1903                    (354203:train.py:326)
00:21:00.348 [I] Progress on: 238it/30.0kit rate:6.5s/it remaining:53:43:08 elapsed:25:15 postfix:- (354203:tqdm_logging.py:145)
00:21:00.349 [I] Step 238: grad_norm=4.1273, loss=0.5463, param_norm=1403.1903                    (354203:train.py:326)
00:21:06.625 [I] Step 239: grad_norm=9.3818, loss=0.5609, param_norm=1403.1903                    (354203:train.py:326)
00:21:12.956 [I] Progress on: 240it/30.0kit rate:6.4s/it remaining:52:52:22 elapsed:25:27 postfix:- (354203:tqdm_logging.py:145)
00:21:12.957 [I] Step 240: grad_norm=8.1800, loss=0.5449, param_norm=1403.1904                    (354203:train.py:326)
00:21:19.204 [I] Step 241: grad_norm=5.2637, loss=0.5484, param_norm=1403.1904                    (354203:train.py:326)
00:21:25.505 [I] Progress on: 242it/30.0kit rate:6.3s/it remaining:52:22:48 elapsed:25:40 postfix:- (354203:tqdm_logging.py:145)
00:21:25.506 [I] Step 242: grad_norm=5.3446, loss=0.5367, param_norm=1403.1904                    (354203:train.py:326)
00:21:31.785 [I] Step 243: grad_norm=8.9497, loss=0.5396, param_norm=1403.1904                    (354203:train.py:326)
00:21:38.089 [I] Progress on: 244it/30.0kit rate:6.3s/it remaining:52:15:21 elapsed:25:53 postfix:- (354203:tqdm_logging.py:145)
00:21:38.089 [I] Step 244: grad_norm=8.2985, loss=0.5244, param_norm=1403.1904                    (354203:train.py:326)
00:21:44.347 [I] Step 245: grad_norm=6.0852, loss=0.5725, param_norm=1403.1903                    (354203:train.py:326)
00:21:50.639 [I] Progress on: 246it/30.0kit rate:6.3s/it remaining:52:05:06 elapsed:26:05 postfix:- (354203:tqdm_logging.py:145)
00:21:50.640 [I] Step 246: grad_norm=5.9451, loss=0.5305, param_norm=1403.1903                    (354203:train.py:326)
00:21:56.903 [I] Step 247: grad_norm=9.0650, loss=0.5118, param_norm=1403.1903                    (354203:train.py:326)
00:22:03.232 [I] Progress on: 248it/30.0kit rate:6.3s/it remaining:52:01:20 elapsed:26:18 postfix:- (354203:tqdm_logging.py:145)
00:22:03.233 [I] Step 248: grad_norm=7.0826, loss=0.5042, param_norm=1403.1903                    (354203:train.py:326)
00:22:09.480 [I] Step 249: grad_norm=8.6927, loss=0.5057, param_norm=1403.1903                    (354203:train.py:326)
00:22:15.774 [I] Progress on: 250it/30.0kit rate:6.3s/it remaining:51:57:20 elapsed:26:30 postfix:- (354203:tqdm_logging.py:145)
00:22:15.775 [I] Step 250: grad_norm=8.0614, loss=0.5003, param_norm=1403.1903                    (354203:train.py:326)
00:22:22.052 [I] Step 251: grad_norm=8.2561, loss=0.4991, param_norm=1403.1904                    (354203:train.py:326)
00:22:28.390 [I] Progress on: 252it/30.0kit rate:6.3s/it remaining:51:59:58 elapsed:26:43 postfix:- (354203:tqdm_logging.py:145)
00:22:28.391 [I] Step 252: grad_norm=7.1462, loss=0.5096, param_norm=1403.1904                    (354203:train.py:326)
00:22:34.650 [I] Step 253: grad_norm=8.0484, loss=0.4878, param_norm=1403.1904                    (354203:train.py:326)
00:22:40.935 [I] Progress on: 254it/30.0kit rate:6.3s/it remaining:51:56:46 elapsed:26:55 postfix:- (354203:tqdm_logging.py:145)
00:22:40.936 [I] Step 254: grad_norm=7.1875, loss=0.4781, param_norm=1403.1904                    (354203:train.py:326)
00:22:48.082 [I] Step 255: grad_norm=10.2152, loss=0.4837, param_norm=1403.1904                   (354203:train.py:326)
00:22:54.330 [I] Progress on: 256it/30.0kit rate:6.5s/it remaining:53:21:46 elapsed:27:09 postfix:- (354203:tqdm_logging.py:145)
00:22:54.331 [I] Step 256: grad_norm=10.9581, loss=0.4793, param_norm=1403.1904                   (354203:train.py:326)
00:23:00.574 [I] Step 257: grad_norm=5.7500, loss=0.4638, param_norm=1403.1904                    (354203:train.py:326)
00:23:06.840 [I] Progress on: 258it/30.0kit rate:6.3s/it remaining:52:27:33 elapsed:27:21 postfix:- (354203:tqdm_logging.py:145)
00:23:06.841 [I] Step 258: grad_norm=5.4080, loss=0.4728, param_norm=1403.1904                    (354203:train.py:326)
00:23:13.235 [I] Step 259: grad_norm=9.3716, loss=0.4596, param_norm=1403.1904                    (354203:train.py:326)
00:23:19.495 [I] Progress on: 260it/30.0kit rate:6.3s/it remaining:52:20:00 elapsed:27:34 postfix:- (354203:tqdm_logging.py:145)
00:23:19.496 [I] Step 260: grad_norm=3.9509, loss=0.4425, param_norm=1403.1904                    (354203:train.py:326)
00:23:25.752 [I] Step 261: grad_norm=13.8839, loss=0.4799, param_norm=1403.1904                   (354203:train.py:326)
00:23:32.009 [I] Progress on: 262it/30.0kit rate:6.3s/it remaining:52:00:08 elapsed:27:46 postfix:- (354203:tqdm_logging.py:145)
00:23:32.009 [I] Step 262: grad_norm=12.5592, loss=0.4835, param_norm=1403.1904                   (354203:train.py:326)
00:23:38.392 [I] Step 263: grad_norm=10.6964, loss=0.4499, param_norm=1403.1904                   (354203:train.py:326)
00:23:44.666 [I] Progress on: 264it/30.0kit rate:6.3s/it remaining:52:04:19 elapsed:27:59 postfix:- (354203:tqdm_logging.py:145)
00:23:44.666 [I] Step 264: grad_norm=10.5367, loss=0.4341, param_norm=1403.1904                   (354203:train.py:326)
00:23:50.926 [I] Step 265: grad_norm=7.5975, loss=0.4367, param_norm=1403.1906                    (354203:train.py:326)
00:23:57.167 [I] Progress on: 266it/30.0kit rate:6.3s/it remaining:51:54:14 elapsed:28:12 postfix:- (354203:tqdm_logging.py:145)
00:23:57.167 [I] Step 266: grad_norm=6.3514, loss=0.4417, param_norm=1403.1906                    (354203:train.py:326)
00:24:03.523 [I] Step 267: grad_norm=12.4162, loss=0.4888, param_norm=1403.1907                   (354203:train.py:326)
00:24:09.756 [I] Progress on: 268it/30.0kit rate:6.3s/it remaining:51:55:02 elapsed:28:24 postfix:- (354203:tqdm_logging.py:145)
00:24:09.756 [I] Step 268: grad_norm=10.7659, loss=0.4345, param_norm=1403.1907                   (354203:train.py:326)
00:24:15.989 [I] Step 269: grad_norm=6.2768, loss=0.4332, param_norm=1403.1907                    (354203:train.py:326)
00:24:22.227 [I] Progress on: 270it/30.0kit rate:6.3s/it remaining:51:41:21 elapsed:28:37 postfix:- (354203:tqdm_logging.py:145)
00:24:22.228 [I] Step 270: grad_norm=6.0614, loss=0.4139, param_norm=1403.1907                    (354203:train.py:326)
00:24:28.515 [I] Step 271: grad_norm=9.4302, loss=0.4311, param_norm=1403.1907                    (354203:train.py:326)
00:24:35.651 [I] Progress on: 272it/30.0kit rate:6.5s/it remaining:53:53:33 elapsed:28:50 postfix:- (354203:tqdm_logging.py:145)
00:24:35.651 [I] Step 272: grad_norm=8.0196, loss=0.4053, param_norm=1403.1907                    (354203:train.py:326)
00:24:41.891 [I] Step 273: grad_norm=7.6146, loss=0.4018, param_norm=1403.1908                    (354203:train.py:326)
00:24:48.135 [I] Progress on: 274it/30.0kit rate:6.4s/it remaining:52:42:24 elapsed:29:03 postfix:- (354203:tqdm_logging.py:145)
00:24:48.135 [I] Step 274: grad_norm=7.2190, loss=0.4200, param_norm=1403.1908                    (354203:train.py:326)
00:24:54.371 [I] Step 275: grad_norm=9.0352, loss=0.4231, param_norm=1403.1908                    (354203:train.py:326)
00:25:00.652 [I] Progress on: 276it/30.0kit rate:6.3s/it remaining:52:09:57 elapsed:29:15 postfix:- (354203:tqdm_logging.py:145)
00:25:00.653 [I] Step 276: grad_norm=7.6066, loss=0.4186, param_norm=1403.1908                    (354203:train.py:326)
00:25:07.001 [I] Step 277: grad_norm=6.0862, loss=0.4258, param_norm=1403.1908                    (354203:train.py:326)
00:25:13.260 [I] Progress on: 278it/30.0kit rate:6.3s/it remaining:52:04:07 elapsed:29:28 postfix:- (354203:tqdm_logging.py:145)
00:25:13.260 [I] Step 278: grad_norm=4.3900, loss=0.4363, param_norm=1403.1909                    (354203:train.py:326)
00:25:19.516 [I] Step 279: grad_norm=7.6543, loss=0.4052, param_norm=1403.1909                    (354203:train.py:326)
00:25:25.804 [I] Progress on: 280it/30.0kit rate:6.3s/it remaining:51:57:46 elapsed:29:40 postfix:- (354203:tqdm_logging.py:145)
00:25:25.804 [I] Step 280: grad_norm=8.0729, loss=0.4065, param_norm=1403.1909                    (354203:train.py:326)
00:25:32.150 [I] Step 281: grad_norm=3.2235, loss=0.4043, param_norm=1403.1909                    (354203:train.py:326)
00:25:38.424 [I] Progress on: 282it/30.0kit rate:6.3s/it remaining:51:56:34 elapsed:29:53 postfix:- (354203:tqdm_logging.py:145)
00:25:38.424 [I] Step 282: grad_norm=4.6847, loss=0.3928, param_norm=1403.1909                    (354203:train.py:326)
00:25:44.672 [I] Step 283: grad_norm=2.3655, loss=0.4570, param_norm=1403.1909                    (354203:train.py:326)
00:25:50.968 [I] Progress on: 284it/30.0kit rate:6.3s/it remaining:51:54:35 elapsed:30:05 postfix:- (354203:tqdm_logging.py:145)
00:25:50.968 [I] Step 284: grad_norm=6.4126, loss=0.4074, param_norm=1403.1910                    (354203:train.py:326)
00:25:57.144 [I] Step 285: grad_norm=3.0514, loss=0.3809, param_norm=1403.1910                    (354203:train.py:326)
00:26:03.391 [I] Progress on: 286it/30.0kit rate:6.2s/it remaining:51:29:59 elapsed:30:18 postfix:- (354203:tqdm_logging.py:145)
00:26:03.392 [I] Step 286: grad_norm=6.6276, loss=0.3948, param_norm=1403.1910                    (354203:train.py:326)
00:26:09.657 [I] Step 287: grad_norm=5.7443, loss=0.4389, param_norm=1403.1912                    (354203:train.py:326)
00:26:15.940 [I] Progress on: 288it/30.0kit rate:6.3s/it remaining:51:41:04 elapsed:30:30 postfix:- (354203:tqdm_logging.py:145)
00:26:15.940 [I] Step 288: grad_norm=3.0521, loss=0.3919, param_norm=1403.1912                    (354203:train.py:326)
00:26:23.010 [I] Step 289: grad_norm=8.6138, loss=0.4182, param_norm=1403.1912                    (354203:train.py:326)
00:26:29.226 [I] Progress on: 290it/30.0kit rate:6.4s/it remaining:53:00:09 elapsed:30:44 postfix:- (354203:tqdm_logging.py:145)
00:26:29.226 [I] Step 290: grad_norm=6.3633, loss=0.3866, param_norm=1403.1913                    (354203:train.py:326)
00:26:35.496 [I] Step 291: grad_norm=7.5974, loss=0.4285, param_norm=1403.1913                    (354203:train.py:326)
00:26:41.729 [I] Progress on: 292it/30.0kit rate:6.3s/it remaining:52:14:07 elapsed:30:56 postfix:- (354203:tqdm_logging.py:145)
00:26:41.730 [I] Step 292: grad_norm=4.9286, loss=0.4009, param_norm=1403.1913                    (354203:train.py:326)
00:26:48.027 [I] Step 293: grad_norm=8.7059, loss=0.3941, param_norm=1403.1913                    (354203:train.py:326)
00:26:54.272 [I] Progress on: 294it/30.0kit rate:6.3s/it remaining:51:56:23 elapsed:31:09 postfix:- (354203:tqdm_logging.py:145)
00:26:54.273 [I] Step 294: grad_norm=8.1585, loss=0.4117, param_norm=1403.1913                    (354203:train.py:326)
00:27:00.587 [I] Step 295: grad_norm=6.2015, loss=0.3756, param_norm=1403.1914                    (354203:train.py:326)
00:27:06.831 [I] Progress on: 296it/30.0kit rate:6.3s/it remaining:51:50:25 elapsed:31:21 postfix:- (354203:tqdm_logging.py:145)
00:27:06.832 [I] Step 296: grad_norm=4.0238, loss=0.3771, param_norm=1403.1913                    (354203:train.py:326)
00:27:13.127 [I] Step 297: grad_norm=9.3269, loss=0.4203, param_norm=1403.1913                    (354203:train.py:326)
00:27:19.361 [I] Progress on: 298it/30.0kit rate:6.3s/it remaining:51:45:27 elapsed:31:34 postfix:- (354203:tqdm_logging.py:145)
00:27:19.362 [I] Step 298: grad_norm=7.8723, loss=0.3621, param_norm=1403.1914                    (354203:train.py:326)
00:27:25.684 [I] Step 299: grad_norm=4.3258, loss=0.3715, param_norm=1403.1913                    (354203:train.py:326)
00:27:31.935 [I] Progress on: 300it/30.0kit rate:6.3s/it remaining:51:45:02 elapsed:31:46 postfix:- (354203:tqdm_logging.py:145)
00:27:31.936 [I] Step 300: grad_norm=2.9398, loss=0.4075, param_norm=1403.1914                    (354203:train.py:326)
00:27:38.253 [I] Step 301: grad_norm=7.2874, loss=0.3661, param_norm=1403.1914                    (354203:train.py:326)
00:27:44.495 [I] Progress on: 302it/30.0kit rate:6.3s/it remaining:51:46:27 elapsed:31:59 postfix:- (354203:tqdm_logging.py:145)
00:27:44.495 [I] Step 302: grad_norm=6.3787, loss=0.3865, param_norm=1403.1915                    (354203:train.py:326)
00:27:50.801 [I] Step 303: grad_norm=4.3465, loss=0.3758, param_norm=1403.1915                    (354203:train.py:326)
00:27:57.068 [I] Progress on: 304it/30.0kit rate:6.3s/it remaining:51:44:49 elapsed:32:11 postfix:- (354203:tqdm_logging.py:145)
00:27:57.069 [I] Step 304: grad_norm=2.3802, loss=0.3868, param_norm=1403.1917                    (354203:train.py:326)
00:28:03.353 [I] Step 305: grad_norm=6.8832, loss=0.3689, param_norm=1403.1917                    (354203:train.py:326)
00:28:10.436 [I] Progress on: 306it/30.0kit rate:6.5s/it remaining:53:51:29 elapsed:32:25 postfix:- (354203:tqdm_logging.py:145)
00:28:10.436 [I] Step 306: grad_norm=5.7206, loss=0.3758, param_norm=1403.1917                    (354203:train.py:326)
00:28:16.646 [I] Step 307: grad_norm=4.5115, loss=0.3975, param_norm=1403.1917                    (354203:train.py:326)
00:28:22.909 [I] Progress on: 308it/30.0kit rate:6.4s/it remaining:52:36:42 elapsed:32:37 postfix:- (354203:tqdm_logging.py:145)
00:28:22.910 [I] Step 308: grad_norm=5.3056, loss=0.3806, param_norm=1403.1917                    (354203:train.py:326)
00:28:29.127 [I] Step 309: grad_norm=6.3311, loss=0.3901, param_norm=1403.1918                    (354203:train.py:326)
00:28:35.415 [I] Progress on: 310it/30.0kit rate:6.3s/it remaining:52:06:41 elapsed:32:50 postfix:- (354203:tqdm_logging.py:145)
00:28:35.416 [I] Step 310: grad_norm=5.3166, loss=0.3812, param_norm=1403.1918                    (354203:train.py:326)
00:28:41.661 [I] Step 311: grad_norm=5.3604, loss=0.3610, param_norm=1403.1918                    (354203:train.py:326)
00:28:47.944 [I] Progress on: 312it/30.0kit rate:6.3s/it remaining:51:52:12 elapsed:33:02 postfix:- (354203:tqdm_logging.py:145)
00:28:47.945 [I] Step 312: grad_norm=4.7817, loss=0.3664, param_norm=1403.1918                    (354203:train.py:326)
00:28:54.177 [I] Step 313: grad_norm=5.1533, loss=0.3728, param_norm=1403.1918                    (354203:train.py:326)
00:29:00.468 [I] Progress on: 314it/30.0kit rate:6.3s/it remaining:51:48:52 elapsed:33:15 postfix:- (354203:tqdm_logging.py:145)
00:29:00.468 [I] Step 314: grad_norm=4.5488, loss=0.3590, param_norm=1403.1918                    (354203:train.py:326)
00:29:06.707 [I] Step 315: grad_norm=4.6705, loss=0.3717, param_norm=1403.1918                    (354203:train.py:326)
00:29:12.975 [I] Progress on: 316it/30.0kit rate:6.3s/it remaining:51:39:19 elapsed:33:27 postfix:- (354203:tqdm_logging.py:145)
00:29:12.976 [I] Step 316: grad_norm=4.4041, loss=0.3690, param_norm=1403.1919                    (354203:train.py:326)
00:29:19.238 [I] Step 317: grad_norm=5.5778, loss=0.4203, param_norm=1403.1920                    (354203:train.py:326)
00:29:25.600 [I] Progress on: 318it/30.0kit rate:6.3s/it remaining:51:50:30 elapsed:33:40 postfix:- (354203:tqdm_logging.py:145)
00:29:25.600 [I] Step 318: grad_norm=4.5246, loss=0.3630, param_norm=1403.1920                    (354203:train.py:326)
00:29:31.835 [I] Step 319: grad_norm=4.1824, loss=0.4364, param_norm=1403.1920                    (354203:train.py:326)
00:29:38.102 [I] Progress on: 320it/30.0kit rate:6.3s/it remaining:51:44:20 elapsed:33:53 postfix:- (354203:tqdm_logging.py:145)
00:29:38.102 [I] Step 320: grad_norm=4.7432, loss=0.3718, param_norm=1403.1920                    (354203:train.py:326)
00:29:44.336 [I] Step 321: grad_norm=4.7070, loss=0.3452, param_norm=1403.1920                    (354203:train.py:326)
00:29:50.613 [I] Progress on: 322it/30.0kit rate:6.3s/it remaining:51:38:20 elapsed:34:05 postfix:- (354203:tqdm_logging.py:145)
00:29:50.613 [I] Step 322: grad_norm=3.3561, loss=0.3734, param_norm=1403.1921                    (354203:train.py:326)
00:29:57.667 [I] Step 323: grad_norm=5.7087, loss=0.3982, param_norm=1403.1921                    (354203:train.py:326)
00:30:03.949 [I] Progress on: 324it/30.0kit rate:6.4s/it remaining:53:04:08 elapsed:34:18 postfix:- (354203:tqdm_logging.py:145)
00:30:03.950 [I] Step 324: grad_norm=5.5148, loss=0.4134, param_norm=1403.1921                    (354203:train.py:326)
00:30:10.224 [I] Step 325: grad_norm=3.6569, loss=0.3670, param_norm=1403.1921                    (354203:train.py:326)
00:30:16.481 [I] Progress on: 326it/30.0kit rate:6.3s/it remaining:52:17:35 elapsed:34:31 postfix:- (354203:tqdm_logging.py:145)
00:30:16.481 [I] Step 326: grad_norm=3.2426, loss=0.3807, param_norm=1403.1921                    (354203:train.py:326)
00:30:22.749 [I] Step 327: grad_norm=5.3228, loss=0.3927, param_norm=1403.1923                    (354203:train.py:326)
00:30:29.040 [I] Progress on: 328it/30.0kit rate:6.3s/it remaining:52:01:55 elapsed:34:43 postfix:- (354203:tqdm_logging.py:145)
00:30:29.041 [I] Step 328: grad_norm=4.7000, loss=0.3736, param_norm=1403.1923                    (354203:train.py:326)
00:30:35.305 [I] Step 329: grad_norm=4.9518, loss=0.3954, param_norm=1403.1923                    (354203:train.py:326)
00:30:41.541 [I] Progress on: 330it/30.0kit rate:6.3s/it remaining:51:46:31 elapsed:34:56 postfix:- (354203:tqdm_logging.py:145)
00:30:41.541 [I] Step 330: grad_norm=4.3657, loss=0.3907, param_norm=1403.1924                    (354203:train.py:326)
00:30:47.806 [I] Step 331: grad_norm=4.2142, loss=0.3766, param_norm=1403.1924                    (354203:train.py:326)
00:30:54.093 [I] Progress on: 332it/30.0kit rate:6.3s/it remaining:51:44:10 elapsed:35:09 postfix:- (354203:tqdm_logging.py:145)
00:30:54.093 [I] Step 332: grad_norm=3.1536, loss=0.3482, param_norm=1403.1924                    (354203:train.py:326)
00:31:00.388 [I] Step 333: grad_norm=6.1947, loss=0.4072, param_norm=1403.1925                    (354203:train.py:326)
00:31:06.649 [I] Progress on: 334it/30.0kit rate:6.3s/it remaining:51:41:05 elapsed:35:21 postfix:- (354203:tqdm_logging.py:145)
00:31:06.649 [I] Step 334: grad_norm=5.9272, loss=0.3680, param_norm=1403.1925                    (354203:train.py:326)
00:31:12.947 [I] Step 335: grad_norm=4.4423, loss=0.3594, param_norm=1403.1925                    (354203:train.py:326)
00:31:19.260 [I] Progress on: 336it/30.0kit rate:6.3s/it remaining:51:48:13 elapsed:35:34 postfix:- (354203:tqdm_logging.py:145)
00:31:19.260 [I] Step 336: grad_norm=4.2493, loss=0.3897, param_norm=1403.1925                    (354203:train.py:326)
00:31:25.559 [I] Step 337: grad_norm=3.9166, loss=0.3735, param_norm=1403.1926                    (354203:train.py:326)
00:31:31.831 [I] Progress on: 338it/30.0kit rate:6.3s/it remaining:51:46:47 elapsed:35:46 postfix:- (354203:tqdm_logging.py:145)
00:31:31.832 [I] Step 338: grad_norm=3.4312, loss=0.3549, param_norm=1403.1926                    (354203:train.py:326)
00:31:38.145 [I] Step 339: grad_norm=5.2147, loss=0.3636, param_norm=1403.1926                    (354203:train.py:326)
00:31:45.219 [I] Progress on: 340it/30.0kit rate:6.5s/it remaining:53:47:12 elapsed:36:00 postfix:- (354203:tqdm_logging.py:145)
00:31:45.219 [I] Step 340: grad_norm=4.9209, loss=0.3521, param_norm=1403.1926                    (354203:train.py:326)
00:31:51.516 [I] Step 341: grad_norm=4.4405, loss=0.3529, param_norm=1403.1926                    (354203:train.py:326)
00:31:57.812 [I] Progress on: 342it/30.0kit rate:6.4s/it remaining:52:48:42 elapsed:36:12 postfix:- (354203:tqdm_logging.py:145)
00:31:57.812 [I] Step 342: grad_norm=4.3349, loss=0.3701, param_norm=1403.1927                    (354203:train.py:326)
00:32:04.064 [I] Step 343: grad_norm=4.1465, loss=0.3782, param_norm=1403.1927                    (354203:train.py:326)
00:32:10.370 [I] Progress on: 344it/30.0kit rate:6.3s/it remaining:52:17:23 elapsed:36:25 postfix:- (354203:tqdm_logging.py:145)
00:32:10.371 [I] Step 344: grad_norm=5.9485, loss=0.4037, param_norm=1403.1927                    (354203:train.py:326)
00:32:16.647 [I] Step 345: grad_norm=2.0274, loss=0.3687, param_norm=1403.1927                    (354203:train.py:326)
00:32:22.929 [I] Progress on: 346it/30.0kit rate:6.3s/it remaining:52:00:58 elapsed:36:37 postfix:- (354203:tqdm_logging.py:145)
00:32:22.929 [I] Step 346: grad_norm=2.7606, loss=0.3525, param_norm=1403.1927                    (354203:train.py:326)
00:32:29.183 [I] Step 347: grad_norm=2.6600, loss=0.3741, param_norm=1403.1927                    (354203:train.py:326)
00:32:35.522 [I] Progress on: 348it/30.0kit rate:6.3s/it remaining:51:56:22 elapsed:36:50 postfix:- (354203:tqdm_logging.py:145)
00:32:35.523 [I] Step 348: grad_norm=2.3054, loss=0.3694, param_norm=1403.1927                    (354203:train.py:326)
00:32:41.817 [I] Step 349: grad_norm=1.8621, loss=0.3682, param_norm=1403.1927                    (354203:train.py:326)
00:32:48.107 [I] Progress on: 350it/30.0kit rate:6.3s/it remaining:51:53:16 elapsed:37:03 postfix:- (354203:tqdm_logging.py:145)
00:32:48.107 [I] Step 350: grad_norm=2.4541, loss=0.3764, param_norm=1403.1927                    (354203:train.py:326)
00:32:54.365 [I] Step 351: grad_norm=2.3697, loss=0.3754, param_norm=1403.1929                    (354203:train.py:326)
00:33:00.691 [I] Progress on: 352it/30.0kit rate:6.3s/it remaining:51:49:50 elapsed:37:15 postfix:- (354203:tqdm_logging.py:145)
00:33:00.691 [I] Step 352: grad_norm=3.3256, loss=0.3817, param_norm=1403.1929                    (354203:train.py:326)
00:33:06.969 [I] Step 353: grad_norm=2.5003, loss=0.3890, param_norm=1403.1929                    (354203:train.py:326)
00:33:13.255 [I] Progress on: 354it/30.0kit rate:6.3s/it remaining:51:48:53 elapsed:37:28 postfix:- (354203:tqdm_logging.py:145)
00:33:13.255 [I] Step 354: grad_norm=3.6826, loss=0.4215, param_norm=1403.1930                    (354203:train.py:326)
00:33:19.507 [I] Step 355: grad_norm=2.7746, loss=0.4048, param_norm=1403.1931                    (354203:train.py:326)
00:33:25.789 [I] Progress on: 356it/30.0kit rate:6.3s/it remaining:51:45:20 elapsed:37:40 postfix:- (354203:tqdm_logging.py:145)
00:33:25.790 [I] Step 356: grad_norm=3.6768, loss=0.3856, param_norm=1403.1931                    (354203:train.py:326)
00:33:32.840 [I] Step 357: grad_norm=3.8203, loss=0.3768, param_norm=1403.1931                    (354203:train.py:326)
00:33:39.139 [I] Progress on: 358it/30.0kit rate:6.4s/it remaining:53:04:16 elapsed:37:54 postfix:- (354203:tqdm_logging.py:145)
00:33:39.140 [I] Step 358: grad_norm=3.9057, loss=0.4039, param_norm=1403.1932                    (354203:train.py:326)
00:33:45.439 [I] Step 359: grad_norm=1.9075, loss=0.3801, param_norm=1403.1932                    (354203:train.py:326)
00:33:51.676 [I] Progress on: 360it/30.0kit rate:6.4s/it remaining:52:21:36 elapsed:38:06 postfix:- (354203:tqdm_logging.py:145)
00:33:51.676 [I] Step 360: grad_norm=4.2264, loss=0.3408, param_norm=1403.1934                    (354203:train.py:326)
00:33:57.954 [I] Step 361: grad_norm=3.4640, loss=0.3557, param_norm=1403.1934                    (354203:train.py:326)
00:34:04.249 [I] Progress on: 362it/30.0kit rate:6.3s/it remaining:52:01:30 elapsed:38:19 postfix:- (354203:tqdm_logging.py:145)
00:34:04.250 [I] Step 362: grad_norm=2.9096, loss=0.3899, param_norm=1403.1935                    (354203:train.py:326)
00:34:10.539 [I] Step 363: grad_norm=2.1718, loss=0.3757, param_norm=1403.1935                    (354203:train.py:326)
00:34:16.790 [I] Progress on: 364it/30.0kit rate:6.3s/it remaining:51:48:32 elapsed:38:31 postfix:- (354203:tqdm_logging.py:145)
00:34:16.791 [I] Step 364: grad_norm=3.5870, loss=0.3646, param_norm=1403.1936                    (354203:train.py:326)
00:34:23.083 [I] Step 365: grad_norm=2.9456, loss=0.3658, param_norm=1403.1936                    (354203:train.py:326)
00:34:29.394 [I] Progress on: 366it/30.0kit rate:6.3s/it remaining:51:50:39 elapsed:38:44 postfix:- (354203:tqdm_logging.py:145)
00:34:29.395 [I] Step 366: grad_norm=3.9907, loss=0.3510, param_norm=1403.1936                    (354203:train.py:326)
00:34:35.678 [I] Step 367: grad_norm=3.0238, loss=0.3654, param_norm=1403.1937                    (354203:train.py:326)
00:34:41.938 [I] Progress on: 368it/30.0kit rate:6.3s/it remaining:51:42:32 elapsed:38:56 postfix:- (354203:tqdm_logging.py:145)
00:34:41.939 [I] Step 368: grad_norm=2.7452, loss=0.3597, param_norm=1403.1938                    (354203:train.py:326)
00:34:48.220 [I] Step 369: grad_norm=2.9731, loss=0.3685, param_norm=1403.1938                    (354203:train.py:326)
00:34:54.508 [I] Progress on: 370it/30.0kit rate:6.3s/it remaining:51:44:48 elapsed:39:09 postfix:- (354203:tqdm_logging.py:145)
00:34:54.509 [I] Step 370: grad_norm=5.4781, loss=0.3740, param_norm=1403.1940                    (354203:train.py:326)
00:35:00.787 [I] Step 371: grad_norm=3.8102, loss=0.3581, param_norm=1403.1940                    (354203:train.py:326)
00:35:07.053 [I] Progress on: 372it/30.0kit rate:6.3s/it remaining:51:37:56 elapsed:39:21 postfix:- (354203:tqdm_logging.py:145)
00:35:07.054 [I] Step 372: grad_norm=7.9568, loss=0.3545, param_norm=1403.1941                    (354203:train.py:326)
00:35:13.342 [I] Step 373: grad_norm=5.4106, loss=0.3727, param_norm=1403.1941                    (354203:train.py:326)
00:35:20.446 [I] Progress on: 374it/30.0kit rate:6.5s/it remaining:53:43:49 elapsed:39:35 postfix:- (354203:tqdm_logging.py:145)
00:35:20.447 [I] Step 374: grad_norm=7.5721, loss=0.3710, param_norm=1403.1942                    (354203:train.py:326)
00:35:26.727 [I] Step 375: grad_norm=7.2699, loss=0.3612, param_norm=1403.1942                    (354203:train.py:326)
00:35:32.965 [I] Progress on: 376it/30.0kit rate:6.4s/it remaining:52:36:22 elapsed:39:47 postfix:- (354203:tqdm_logging.py:145)
00:35:32.965 [I] Step 376: grad_norm=3.4457, loss=0.3533, param_norm=1403.1943                    (354203:train.py:326)
00:35:39.221 [I] Step 377: grad_norm=3.6913, loss=0.3822, param_norm=1403.1943                    (354203:train.py:326)
00:35:45.546 [I] Progress on: 378it/30.0kit rate:6.3s/it remaining:52:12:45 elapsed:40:00 postfix:- (354203:tqdm_logging.py:145)
00:35:45.547 [I] Step 378: grad_norm=4.3797, loss=0.3453, param_norm=1403.1943                    (354203:train.py:326)
00:35:51.830 [I] Step 379: grad_norm=2.7586, loss=0.3641, param_norm=1403.1945                    (354203:train.py:326)
00:35:58.067 [I] Progress on: 380it/30.0kit rate:6.3s/it remaining:51:50:50 elapsed:40:12 postfix:- (354203:tqdm_logging.py:145)
00:35:58.067 [I] Step 380: grad_norm=6.2009, loss=0.3487, param_norm=1403.1946                    (354203:train.py:326)
00:36:04.321 [I] Step 381: grad_norm=4.6487, loss=0.3578, param_norm=1403.1945                    (354203:train.py:326)
00:36:10.654 [I] Progress on: 382it/30.0kit rate:6.3s/it remaining:51:48:50 elapsed:40:25 postfix:- (354203:tqdm_logging.py:145)
00:36:10.654 [I] Step 382: grad_norm=5.6952, loss=0.4040, param_norm=1403.1946                    (354203:train.py:326)
00:36:16.948 [I] Step 383: grad_norm=5.3331, loss=0.3585, param_norm=1403.1946                    (354203:train.py:326)
00:36:23.208 [I] Progress on: 384it/30.0kit rate:6.3s/it remaining:51:41:36 elapsed:40:38 postfix:- (354203:tqdm_logging.py:145)
00:36:23.209 [I] Step 384: grad_norm=3.8762, loss=0.3680, param_norm=1403.1946                    (354203:train.py:326)
00:36:29.464 [I] Step 385: grad_norm=3.6549, loss=0.3699, param_norm=1403.1947                    (354203:train.py:326)
00:36:35.806 [I] Progress on: 386it/30.0kit rate:6.3s/it remaining:51:47:36 elapsed:40:50 postfix:- (354203:tqdm_logging.py:145)
00:36:35.806 [I] Step 386: grad_norm=4.9221, loss=0.3579, param_norm=1403.1947                    (354203:train.py:326)
00:36:42.097 [I] Step 387: grad_norm=4.3574, loss=0.3705, param_norm=1403.1947                    (354203:train.py:326)
00:36:48.351 [I] Progress on: 388it/30.0kit rate:6.3s/it remaining:51:40:31 elapsed:41:03 postfix:- (354203:tqdm_logging.py:145)
00:36:48.352 [I] Step 388: grad_norm=4.5289, loss=0.3593, param_norm=1403.1947                    (354203:train.py:326)
00:36:54.615 [I] Step 389: grad_norm=4.0959, loss=0.3663, param_norm=1403.1948                    (354203:train.py:326)
00:37:00.897 [I] Progress on: 390it/30.0kit rate:6.3s/it remaining:51:37:52 elapsed:41:15 postfix:- (354203:tqdm_logging.py:145)
00:37:00.898 [I] Step 390: grad_norm=5.4100, loss=0.3669, param_norm=1403.1948                    (354203:train.py:326)
00:37:07.962 [I] Step 391: grad_norm=3.4179, loss=0.3457, param_norm=1403.1949                    (354203:train.py:326)
00:37:14.238 [I] Progress on: 392it/30.0kit rate:6.4s/it remaining:53:00:26 elapsed:41:29 postfix:- (354203:tqdm_logging.py:145)
00:37:14.238 [I] Step 392: grad_norm=4.5563, loss=0.3999, param_norm=1403.1949                    (354203:train.py:326)
00:37:20.516 [I] Step 393: grad_norm=3.9737, loss=0.3444, param_norm=1403.1949                    (354203:train.py:326)
00:37:26.753 [I] Progress on: 394it/30.0kit rate:6.4s/it remaining:52:13:56 elapsed:41:41 postfix:- (354203:tqdm_logging.py:145)
00:37:26.754 [I] Step 394: grad_norm=4.6757, loss=0.3664, param_norm=1403.1949                    (354203:train.py:326)
00:37:33.032 [I] Step 395: grad_norm=4.2901, loss=0.3642, param_norm=1403.1949                    (354203:train.py:326)
00:37:39.345 [I] Progress on: 396it/30.0kit rate:6.3s/it remaining:51:56:54 elapsed:41:54 postfix:- (354203:tqdm_logging.py:145)
00:37:39.346 [I] Step 396: grad_norm=3.1077, loss=0.3733, param_norm=1403.1951                    (354203:train.py:326)
00:37:45.641 [I] Step 397: grad_norm=2.3289, loss=0.3492, param_norm=1403.1951                    (354203:train.py:326)
00:37:51.901 [I] Progress on: 398it/30.0kit rate:6.3s/it remaining:51:46:40 elapsed:42:06 postfix:- (354203:tqdm_logging.py:145)
00:37:51.902 [I] Step 398: grad_norm=3.8333, loss=0.3445, param_norm=1403.1951                    (354203:train.py:326)
00:37:58.184 [I] Step 399: grad_norm=3.6273, loss=0.3759, param_norm=1403.1951                    (354203:train.py:326)
00:38:04.480 [I] Progress on: 400it/30.0kit rate:6.3s/it remaining:51:46:18 elapsed:42:19 postfix:- (354203:tqdm_logging.py:145)
00:38:04.481 [I] Step 400: grad_norm=3.8673, loss=0.3521, param_norm=1403.1952                    (354203:train.py:326)
00:38:10.772 [I] Step 401: grad_norm=2.0237, loss=0.3679, param_norm=1403.1952                    (354203:train.py:326)
00:38:17.027 [I] Progress on: 402it/30.0kit rate:6.3s/it remaining:51:39:09 elapsed:42:31 postfix:- (354203:tqdm_logging.py:145)
00:38:17.027 [I] Step 402: grad_norm=5.8544, loss=0.3530, param_norm=1403.1952                    (354203:train.py:326)
00:38:23.323 [I] Step 403: grad_norm=4.5609, loss=0.3589, param_norm=1403.1952                    (354203:train.py:326)
00:38:29.625 [I] Progress on: 404it/30.0kit rate:6.3s/it remaining:51:43:12 elapsed:42:44 postfix:- (354203:tqdm_logging.py:145)
00:38:29.625 [I] Step 404: grad_norm=2.8479, loss=0.3747, param_norm=1403.1953                    (354203:train.py:326)
00:38:35.899 [I] Step 405: grad_norm=3.2794, loss=0.3723, param_norm=1403.1953                    (354203:train.py:326)
00:38:42.144 [I] Progress on: 406it/30.0kit rate:6.3s/it remaining:51:35:27 elapsed:42:57 postfix:- (354203:tqdm_logging.py:145)
00:38:42.145 [I] Step 406: grad_norm=2.2503, loss=0.3313, param_norm=1403.1954                    (354203:train.py:326)
00:38:48.427 [I] Step 407: grad_norm=2.3490, loss=0.3634, param_norm=1403.1954                    (354203:train.py:326)
00:38:55.467 [I] Progress on: 408it/30.0kit rate:6.5s/it remaining:53:30:28 elapsed:43:10 postfix:- (354203:tqdm_logging.py:145)
00:38:55.468 [I] Step 408: grad_norm=2.9667, loss=0.3666, param_norm=1403.1956                    (354203:train.py:326)
00:39:01.727 [I] Step 409: grad_norm=2.8491, loss=0.3839, param_norm=1403.1956                    (354203:train.py:326)
00:39:07.996 [I] Progress on: 410it/30.0kit rate:6.4s/it remaining:52:27:18 elapsed:43:22 postfix:- (354203:tqdm_logging.py:145)
00:39:07.996 [I] Step 410: grad_norm=3.1695, loss=0.3632, param_norm=1403.1956                    (354203:train.py:326)
00:39:14.275 [I] Step 411: grad_norm=2.7491, loss=0.3640, param_norm=1403.1956                    (354203:train.py:326)
00:39:20.555 [I] Progress on: 412it/30.0kit rate:6.3s/it remaining:52:00:04 elapsed:43:35 postfix:- (354203:tqdm_logging.py:145)
00:39:20.555 [I] Step 412: grad_norm=3.5337, loss=0.3620, param_norm=1403.1956                    (354203:train.py:326)
00:39:26.829 [I] Step 413: grad_norm=1.8469, loss=0.3701, param_norm=1403.1957                    (354203:train.py:326)
00:39:33.096 [I] Progress on: 414it/30.0kit rate:6.3s/it remaining:51:47:06 elapsed:43:48 postfix:- (354203:tqdm_logging.py:145)
00:39:33.096 [I] Step 414: grad_norm=4.0410, loss=0.3952, param_norm=1403.1958                    (354203:train.py:326)
00:39:39.385 [I] Step 415: grad_norm=3.8333, loss=0.3597, param_norm=1403.1958                    (354203:train.py:326)
00:39:45.657 [I] Progress on: 416it/30.0kit rate:6.3s/it remaining:51:41:20 elapsed:44:00 postfix:- (354203:tqdm_logging.py:145)
00:39:45.658 [I] Step 416: grad_norm=2.7773, loss=0.3800, param_norm=1403.1958                    (354203:train.py:326)
00:39:51.764 [I] Step 417: grad_norm=4.2685, loss=0.3683, param_norm=1403.1958                    (354203:train.py:326)
00:39:58.023 [I] Progress on: 418it/30.0kit rate:6.2s/it remaining:51:12:14 elapsed:44:12 postfix:- (354203:tqdm_logging.py:145)
00:39:58.023 [I] Step 418: grad_norm=2.8587, loss=0.3944, param_norm=1403.1959                    (354203:train.py:326)
00:40:04.316 [I] Step 419: grad_norm=2.8386, loss=0.3561, param_norm=1403.1959                    (354203:train.py:326)
00:40:10.583 [I] Progress on: 420it/30.0kit rate:6.3s/it remaining:51:24:22 elapsed:44:25 postfix:- (354203:tqdm_logging.py:145)
00:40:10.584 [I] Step 420: grad_norm=4.2033, loss=0.3796, param_norm=1403.1960                    (354203:train.py:326)
00:40:16.836 [I] Step 421: grad_norm=2.6217, loss=0.3674, param_norm=1403.1960                    (354203:train.py:326)
00:40:23.100 [I] Progress on: 422it/30.0kit rate:6.3s/it remaining:51:24:07 elapsed:44:38 postfix:- (354203:tqdm_logging.py:145)
00:40:23.100 [I] Step 422: grad_norm=4.1248, loss=0.3748, param_norm=1403.1962                    (354203:train.py:326)
00:40:29.348 [I] Step 423: grad_norm=2.7633, loss=0.3602, param_norm=1403.1962                    (354203:train.py:326)
00:40:35.596 [I] Progress on: 424it/30.0kit rate:6.3s/it remaining:51:23:27 elapsed:44:50 postfix:- (354203:tqdm_logging.py:145)
00:40:35.596 [I] Step 424: grad_norm=3.5746, loss=0.3344, param_norm=1403.1963                    (354203:train.py:326)
00:40:42.663 [I] Step 425: grad_norm=3.4895, loss=0.3678, param_norm=1403.1964                    (354203:train.py:326)
00:40:48.955 [I] Progress on: 426it/30.0kit rate:6.4s/it remaining:52:49:03 elapsed:45:03 postfix:- (354203:tqdm_logging.py:145)
00:40:48.956 [I] Step 426: grad_norm=4.3651, loss=0.4035, param_norm=1403.1964                    (354203:train.py:326)
00:40:55.181 [I] Step 427: grad_norm=3.5280, loss=0.3535, param_norm=1403.1964                    (354203:train.py:326)
00:41:01.424 [I] Progress on: 428it/30.0kit rate:6.3s/it remaining:52:00:30 elapsed:45:16 postfix:- (354203:tqdm_logging.py:145)
00:41:01.425 [I] Step 428: grad_norm=2.1825, loss=0.3509, param_norm=1403.1965                    (354203:train.py:326)
00:41:07.757 [I] Step 429: grad_norm=1.1673, loss=0.3627, param_norm=1403.1965                    (354203:train.py:326)
00:41:14.032 [I] Progress on: 430it/30.0kit rate:6.3s/it remaining:51:53:00 elapsed:45:28 postfix:- (354203:tqdm_logging.py:145)
00:41:14.032 [I] Step 430: grad_norm=1.9619, loss=0.3450, param_norm=1403.1965                    (354203:train.py:326)
00:41:20.290 [I] Step 431: grad_norm=2.5358, loss=0.3577, param_norm=1403.1967                    (354203:train.py:326)
00:41:26.525 [I] Progress on: 432it/30.0kit rate:6.3s/it remaining:51:35:31 elapsed:45:41 postfix:- (354203:tqdm_logging.py:145)
00:41:26.525 [I] Step 432: grad_norm=1.2453, loss=0.3453, param_norm=1403.1968                    (354203:train.py:326)
00:41:32.842 [I] Step 433: grad_norm=1.8590, loss=0.3361, param_norm=1403.1968                    (354203:train.py:326)
00:41:39.128 [I] Progress on: 434it/30.0kit rate:6.3s/it remaining:51:37:25 elapsed:45:54 postfix:- (354203:tqdm_logging.py:145)
00:41:39.129 [I] Step 434: grad_norm=3.4302, loss=0.3661, param_norm=1403.1969                    (354203:train.py:326)
00:41:45.386 [I] Step 435: grad_norm=2.4784, loss=0.3419, param_norm=1403.1969                    (354203:train.py:326)
00:41:51.645 [I] Progress on: 436it/30.0kit rate:6.3s/it remaining:51:29:27 elapsed:46:06 postfix:- (354203:tqdm_logging.py:145)
00:41:51.646 [I] Step 436: grad_norm=2.6511, loss=0.3449, param_norm=1403.1970                    (354203:train.py:326)
00:41:57.982 [I] Step 437: grad_norm=2.3733, loss=0.3668, param_norm=1403.1970                    (354203:train.py:326)
00:42:04.271 [I] Progress on: 438it/30.0kit rate:6.3s/it remaining:51:38:34 elapsed:46:19 postfix:- (354203:tqdm_logging.py:145)
00:42:04.272 [I] Step 438: grad_norm=1.7870, loss=0.3240, param_norm=1403.1971                    (354203:train.py:326)
00:42:10.518 [I] Step 439: grad_norm=2.2846, loss=0.3647, param_norm=1403.1971                    (354203:train.py:326)
00:42:16.777 [I] Progress on: 440it/30.0kit rate:6.3s/it remaining:51:28:46 elapsed:46:31 postfix:- (354203:tqdm_logging.py:145)
00:42:16.778 [I] Step 440: grad_norm=4.3995, loss=0.3414, param_norm=1403.1971                    (354203:train.py:326)
00:42:23.036 [I] Step 441: grad_norm=3.1228, loss=0.3417, param_norm=1403.1973                    (354203:train.py:326)
00:42:30.164 [I] Progress on: 442it/30.0kit rate:6.5s/it remaining:53:34:49 elapsed:46:45 postfix:- (354203:tqdm_logging.py:145)
00:42:30.165 [I] Step 442: grad_norm=2.2863, loss=0.3666, param_norm=1403.1974                    (354203:train.py:326)
00:42:36.409 [I] Step 443: grad_norm=2.2284, loss=0.3800, param_norm=1403.1975                    (354203:train.py:326)
00:42:42.651 [I] Progress on: 444it/30.0kit rate:6.4s/it remaining:52:24:27 elapsed:46:57 postfix:- (354203:tqdm_logging.py:145)
00:42:42.651 [I] Step 444: grad_norm=4.6845, loss=0.3522, param_norm=1403.1975                    (354203:train.py:326)
00:42:48.885 [I] Step 445: grad_norm=2.0667, loss=0.3553, param_norm=1403.1976                    (354203:train.py:326)
00:42:55.245 [I] Progress on: 446it/30.0kit rate:6.3s/it remaining:52:03:41 elapsed:47:10 postfix:- (354203:tqdm_logging.py:145)
00:42:55.245 [I] Step 446: grad_norm=5.2133, loss=0.3944, param_norm=1403.1978                    (354203:train.py:326)
00:43:01.511 [I] Step 447: grad_norm=2.8192, loss=0.3729, param_norm=1403.1978                    (354203:train.py:326)
00:43:07.782 [I] Progress on: 448it/30.0kit rate:6.3s/it remaining:51:43:07 elapsed:47:22 postfix:- (354203:tqdm_logging.py:145)
00:43:07.782 [I] Step 448: grad_norm=5.3327, loss=0.3271, param_norm=1403.1978                    (354203:train.py:326)
00:43:14.046 [I] Step 449: grad_norm=4.8117, loss=0.3502, param_norm=1403.1979                    (354203:train.py:326)
00:43:20.447 [I] Progress on: 450it/30.0kit rate:6.3s/it remaining:51:54:17 elapsed:47:35 postfix:- (354203:tqdm_logging.py:145)
00:43:20.448 [I] Step 450: grad_norm=3.0341, loss=0.3472, param_norm=1403.1979                    (354203:train.py:326)
00:43:26.723 [I] Step 451: grad_norm=4.2427, loss=0.3426, param_norm=1403.1979                    (354203:train.py:326)
00:43:32.992 [I] Progress on: 452it/30.0kit rate:6.3s/it remaining:51:41:17 elapsed:47:47 postfix:- (354203:tqdm_logging.py:145)
00:43:32.992 [I] Step 452: grad_norm=2.7638, loss=0.3537, param_norm=1403.1979                    (354203:train.py:326)
00:43:39.247 [I] Step 453: grad_norm=4.1633, loss=0.3573, param_norm=1403.1979                    (354203:train.py:326)
00:43:45.632 [I] Progress on: 454it/30.0kit rate:6.3s/it remaining:51:51:05 elapsed:48:00 postfix:- (354203:tqdm_logging.py:145)
00:43:45.633 [I] Step 454: grad_norm=3.6153, loss=0.3483, param_norm=1403.1980                    (354203:train.py:326)
00:43:51.880 [I] Step 455: grad_norm=3.7189, loss=0.3622, param_norm=1403.1980                    (354203:train.py:326)
00:43:58.137 [I] Progress on: 456it/30.0kit rate:6.3s/it remaining:51:33:53 elapsed:48:13 postfix:- (354203:tqdm_logging.py:145)
00:43:58.137 [I] Step 456: grad_norm=3.2586, loss=0.3491, param_norm=1403.1981                    (354203:train.py:326)
00:44:04.400 [I] Step 457: grad_norm=4.1035, loss=0.3684, param_norm=1403.1982                    (354203:train.py:326)
00:44:10.701 [I] Progress on: 458it/30.0kit rate:6.3s/it remaining:51:34:02 elapsed:48:25 postfix:- (354203:tqdm_logging.py:145)
00:44:10.701 [I] Step 458: grad_norm=4.2314, loss=0.3641, param_norm=1403.1982                    (354203:train.py:326)
00:44:17.820 [I] Step 459: grad_norm=3.0568, loss=0.3196, param_norm=1403.1984                    (354203:train.py:326)
00:44:24.073 [I] Progress on: 460it/30.0kit rate:6.5s/it remaining:52:55:53 elapsed:48:38 postfix:- (354203:tqdm_logging.py:145)
00:44:24.073 [I] Step 460: grad_norm=5.2961, loss=0.3335, param_norm=1403.1984                    (354203:train.py:326)
00:44:30.319 [I] Step 461: grad_norm=3.7592, loss=0.3502, param_norm=1403.1984                    (354203:train.py:326)
00:44:36.613 [I] Progress on: 462it/30.0kit rate:6.4s/it remaining:52:08:28 elapsed:48:51 postfix:- (354203:tqdm_logging.py:145)
00:44:36.613 [I] Step 462: grad_norm=4.7479, loss=0.3764, param_norm=1403.1985                    (354203:train.py:326)
00:44:42.905 [I] Step 463: grad_norm=3.0471, loss=0.3391, param_norm=1403.1986                    (354203:train.py:326)
00:44:49.210 [I] Progress on: 464it/30.0kit rate:6.3s/it remaining:51:55:20 elapsed:49:04 postfix:- (354203:tqdm_logging.py:145)
00:44:49.211 [I] Step 464: grad_norm=6.0736, loss=0.3822, param_norm=1403.1986                    (354203:train.py:326)
00:44:55.487 [I] Step 465: grad_norm=5.1596, loss=0.3584, param_norm=1403.1987                    (354203:train.py:326)
00:45:01.784 [I] Progress on: 466it/30.0kit rate:6.3s/it remaining:51:43:39 elapsed:49:16 postfix:- (354203:tqdm_logging.py:145)
00:45:01.785 [I] Step 466: grad_norm=5.8716, loss=0.3428, param_norm=1403.1987                    (354203:train.py:326)
00:45:08.081 [I] Step 467: grad_norm=4.9160, loss=0.3539, param_norm=1403.1987                    (354203:train.py:326)
00:45:14.397 [I] Progress on: 468it/30.0kit rate:6.3s/it remaining:51:44:19 elapsed:49:29 postfix:- (354203:tqdm_logging.py:145)
00:45:14.398 [I] Step 468: grad_norm=4.0362, loss=0.3486, param_norm=1403.1989                    (354203:train.py:326)
00:45:20.666 [I] Step 469: grad_norm=3.3080, loss=0.3503, param_norm=1403.1989                    (354203:train.py:326)
00:45:26.951 [I] Progress on: 470it/30.0kit rate:6.3s/it remaining:51:38:21 elapsed:49:41 postfix:- (354203:tqdm_logging.py:145)
00:45:26.951 [I] Step 470: grad_norm=4.2840, loss=0.3872, param_norm=1403.1990                    (354203:train.py:326)
00:45:33.224 [I] Step 471: grad_norm=3.0121, loss=0.3503, param_norm=1403.1990                    (354203:train.py:326)
00:45:39.541 [I] Progress on: 472it/30.0kit rate:6.3s/it remaining:51:36:43 elapsed:49:54 postfix:- (354203:tqdm_logging.py:145)
00:45:39.542 [I] Step 472: grad_norm=3.7703, loss=0.3398, param_norm=1403.1990                    (354203:train.py:326)
00:45:45.809 [I] Step 473: grad_norm=3.1512, loss=0.3302, param_norm=1403.1990                    (354203:train.py:326)
00:45:52.082 [I] Progress on: 474it/30.0kit rate:6.3s/it remaining:51:34:00 elapsed:50:06 postfix:- (354203:tqdm_logging.py:145)
00:45:52.082 [I] Step 474: grad_norm=3.2196, loss=0.3576, param_norm=1403.1991                    (354203:train.py:326)
00:45:58.347 [I] Step 475: grad_norm=3.4733, loss=0.3906, param_norm=1403.1991                    (354203:train.py:326)
00:46:05.444 [I] Progress on: 476it/30.0kit rate:6.5s/it remaining:53:32:08 elapsed:50:20 postfix:- (354203:tqdm_logging.py:145)
00:46:05.444 [I] Step 476: grad_norm=2.9439, loss=0.3316, param_norm=1403.1991                    (354203:train.py:326)
00:46:11.740 [I] Step 477: grad_norm=2.4856, loss=0.3587, param_norm=1403.1991                    (354203:train.py:326)
00:46:18.003 [I] Progress on: 478it/30.0kit rate:6.4s/it remaining:52:27:02 elapsed:50:32 postfix:- (354203:tqdm_logging.py:145)
00:46:18.003 [I] Step 478: grad_norm=3.6424, loss=0.3488, param_norm=1403.1992                    (354203:train.py:326)
00:46:24.280 [I] Step 479: grad_norm=5.2684, loss=0.3427, param_norm=1403.1992                    (354203:train.py:326)
00:46:30.596 [I] Progress on: 480it/30.0kit rate:6.3s/it remaining:52:02:42 elapsed:50:45 postfix:- (354203:tqdm_logging.py:145)
00:46:30.597 [I] Step 480: grad_norm=6.4900, loss=0.3113, param_norm=1403.1995                    (354203:train.py:326)
00:46:36.936 [I] Step 481: grad_norm=6.5689, loss=0.3139, param_norm=1403.1995                    (354203:train.py:326)
00:46:43.215 [I] Progress on: 482it/30.0kit rate:6.3s/it remaining:51:50:15 elapsed:50:58 postfix:- (354203:tqdm_logging.py:145)
00:46:43.215 [I] Step 482: grad_norm=8.0426, loss=0.2662, param_norm=1403.1996                    (354203:train.py:326)
00:46:49.482 [I] Step 483: grad_norm=10.1012, loss=0.2303, param_norm=1403.1996                   (354203:train.py:326)
00:46:55.814 [I] Progress on: 484it/30.0kit rate:6.3s/it remaining:51:47:04 elapsed:51:10 postfix:- (354203:tqdm_logging.py:145)
00:46:55.814 [I] Step 484: grad_norm=10.0199, loss=0.1970, param_norm=1403.1997                   (354203:train.py:326)
00:47:02.145 [I] Step 485: grad_norm=8.8699, loss=0.1708, param_norm=1403.1997                    (354203:train.py:326)
00:47:08.417 [I] Progress on: 486it/30.0kit rate:6.3s/it remaining:51:41:04 elapsed:51:23 postfix:- (354203:tqdm_logging.py:145)
00:47:08.417 [I] Step 486: grad_norm=5.9042, loss=0.1467, param_norm=1403.1997                    (354203:train.py:326)
00:47:14.687 [I] Step 487: grad_norm=17.0508, loss=0.1774, param_norm=1403.1998                   (354203:train.py:326)
00:47:21.024 [I] Progress on: 488it/30.0kit rate:6.3s/it remaining:51:42:01 elapsed:51:35 postfix:- (354203:tqdm_logging.py:145)
00:47:21.025 [I] Step 488: grad_norm=13.6563, loss=0.1324, param_norm=1403.1998                   (354203:train.py:326)
00:47:27.327 [I] Step 489: grad_norm=6.7065, loss=0.1069, param_norm=1403.2001                    (354203:train.py:326)
00:47:33.602 [I] Progress on: 490it/30.0kit rate:6.3s/it remaining:51:35:11 elapsed:51:48 postfix:- (354203:tqdm_logging.py:145)
00:47:33.603 [I] Step 490: grad_norm=6.2509, loss=0.1175, param_norm=1403.2001                    (354203:train.py:326)
00:47:39.835 [I] Step 491: grad_norm=2.9655, loss=0.1028, param_norm=1403.2002                    (354203:train.py:326)
00:47:46.135 [I] Progress on: 492it/30.0kit rate:6.3s/it remaining:51:28:51 elapsed:52:01 postfix:- (354203:tqdm_logging.py:145)
00:47:46.135 [I] Step 492: grad_norm=2.2904, loss=0.0972, param_norm=1403.2002                    (354203:train.py:326)
00:47:53.189 [I] Step 493: grad_norm=8.0836, loss=0.0827, param_norm=1403.2003                    (354203:train.py:326)
00:47:59.455 [I] Progress on: 494it/30.0kit rate:6.4s/it remaining:52:48:56 elapsed:52:14 postfix:- (354203:tqdm_logging.py:145)
00:47:59.455 [I] Step 494: grad_norm=7.8553, loss=0.1012, param_norm=1403.2003                    (354203:train.py:326)
00:48:05.746 [I] Step 495: grad_norm=5.0824, loss=0.0862, param_norm=1403.2004                    (354203:train.py:326)
00:48:11.985 [I] Progress on: 496it/30.0kit rate:6.4s/it remaining:52:03:30 elapsed:52:26 postfix:- (354203:tqdm_logging.py:145)
00:48:11.986 [I] Step 496: grad_norm=2.1128, loss=0.0873, param_norm=1403.2004                    (354203:train.py:326)
00:48:18.254 [I] Step 497: grad_norm=3.8786, loss=0.0778, param_norm=1403.2006                    (354203:train.py:326)
